{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NGS - Quality control, Alignment, Visualisation This course can be done both enrolled (with a teacher) and independently (in your own time). Choose below what applies to you. Enrolled to the course Material This website Zoom meeting (through mail) Google doc (through mail) slack channel Learning outcomes After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output Learning experiences This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only. Exercises Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different. Asking questions During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online): A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #peer-q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. Answer questions only if you have finished the practical block, and use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re stuck and need tutor support, use the no button in Zoom, if you\u2019re finished use the yes button. To summarize: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #peer_q_and_a on slack if really stuck: no button in zoom if finished: yes button in zoom Independently You can do this course completely independently without a teacher. To do the exercises, we will set things up locally with a Docker container. If there any issues, use the issues page on our github repository . Note It might take us a while to respond to issues. Therefore, first check if a similar issue already exists, and/or try to fix it yourself. There\u2019s a lot of documentation/fora/threads on the web! Learning outcomes After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output Exercises Each block has practical work involved. Some more than others. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Home"},{"location":"#ngs-quality-control-alignment-visualisation","text":"This course can be done both enrolled (with a teacher) and independently (in your own time). Choose below what applies to you. Enrolled to the course","title":"NGS - Quality control, Alignment, Visualisation"},{"location":"#material","text":"This website Zoom meeting (through mail) Google doc (through mail) slack channel","title":"Material"},{"location":"#learning-outcomes","text":"After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output","title":"Learning outcomes"},{"location":"#learning-experiences","text":"This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.","title":"Learning experiences"},{"location":"#exercises","text":"Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"#asking-questions","text":"During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online): A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #peer-q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. Answer questions only if you have finished the practical block, and use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re stuck and need tutor support, use the no button in Zoom, if you\u2019re finished use the yes button. To summarize: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #peer_q_and_a on slack if really stuck: no button in zoom if finished: yes button in zoom Independently You can do this course completely independently without a teacher. To do the exercises, we will set things up locally with a Docker container. If there any issues, use the issues page on our github repository . Note It might take us a while to respond to issues. Therefore, first check if a similar issue already exists, and/or try to fix it yourself. There\u2019s a lot of documentation/fora/threads on the web!","title":"Asking questions"},{"location":"#learning-outcomes_1","text":"After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output","title":"Learning outcomes"},{"location":"#exercises_1","text":"Each block has practical work involved. Some more than others. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"course_schedule/","text":"Day 1 block start end subject introduction 9:00 AM 9:30 AM Introduction block 1 9:30 AM 10:30 AM Sequencing technologies 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Quality control 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment Day 2 block start end subject block 1 9:00 AM 10:30 AM File types 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Samtools 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM IGV and visualisation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Group work - organisation Day 3 block start end subject 9:00 AM 3:00 PM Group work 3:30 PM 5:00 PM Presentations","title":"Course schedule"},{"location":"course_schedule/#day-1","text":"block start end subject introduction 9:00 AM 9:30 AM Introduction block 1 9:30 AM 10:30 AM Sequencing technologies 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Quality control 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Read alignment","title":"Day 1"},{"location":"course_schedule/#day-2","text":"block start end subject block 1 9:00 AM 10:30 AM File types 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Samtools 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM IGV and visualisation 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Group work - organisation","title":"Day 2"},{"location":"course_schedule/#day-3","text":"block start end subject 9:00 AM 3:00 PM Group work 3:30 PM 5:00 PM Presentations","title":"Day 3"},{"location":"day3/","text":"Details on organisation and projects can be found at documentation of day 2 . During the projects The time to do the projects is limited, so if you\u2019re stuck: don\u2019t hesitate to ask questions If you have time left, consider to add an evaluation, like: The effect of varying specific arguments The effect of trimming/not trimming Another aligner of your choice","title":"Day 3"},{"location":"day3/#during-the-projects","text":"The time to do the projects is limited, so if you\u2019re stuck: don\u2019t hesitate to ask questions If you have time left, consider to add an evaluation, like: The effect of varying specific arguments The effect of trimming/not trimming Another aligner of your choice","title":"During the projects"},{"location":"precourse/","text":"UNIX As is stated in the course prerequisites at the announcement web page . We expect participants to have a basic understanding of working with the command line on UNIX-based systems. If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial . Software We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server or, if you\u2019re not enrolled in the course in a Docker container. The AWS server behaves like a \u2018normal\u2019 remote server, and can be approached through ssh with a username, key and IP address. All participants will be granted access to a personal home directory. Before the course, make sure you can comfortably work on a remote server. This means that you can approach it through the shell, modify scripts and transfer files. We can recommend atom for Linux and Mac, and Notepad ++ in combination with MobaXterm for Windows. We will be visualising our results with IGV. Therefore, install in your computer (choose Docker if you are doing this course independently): mac OS/Linux SSH and scripting: Atom with packages like: terminus and ftp-remote-edit Transferring files: FileZilla Integrative Genomics Viewer (IGV) Windows SSH and scripting: MobaXterm and/or Notepad++ with the plugin NppFTP Transferring files: FileZilla Integrative Genomics Viewer (IGV) Docker Docker A script editor Atom or Notepad++","title":"Precourse preparations"},{"location":"precourse/#unix","text":"As is stated in the course prerequisites at the announcement web page . We expect participants to have a basic understanding of working with the command line on UNIX-based systems. If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial .","title":"UNIX"},{"location":"precourse/#software","text":"We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server or, if you\u2019re not enrolled in the course in a Docker container. The AWS server behaves like a \u2018normal\u2019 remote server, and can be approached through ssh with a username, key and IP address. All participants will be granted access to a personal home directory. Before the course, make sure you can comfortably work on a remote server. This means that you can approach it through the shell, modify scripts and transfer files. We can recommend atom for Linux and Mac, and Notepad ++ in combination with MobaXterm for Windows. We will be visualising our results with IGV. Therefore, install in your computer (choose Docker if you are doing this course independently): mac OS/Linux SSH and scripting: Atom with packages like: terminus and ftp-remote-edit Transferring files: FileZilla Integrative Genomics Viewer (IGV) Windows SSH and scripting: MobaXterm and/or Notepad++ with the plugin NppFTP Transferring files: FileZilla Integrative Genomics Viewer (IGV) Docker Docker A script editor Atom or Notepad++","title":"Software"},{"location":"day1/intro/","text":"If working independently If you are doing this course independently, you can skip this part. Material Download the presentation Ice-breaker and expectations 30 minutes Write in the Google doc: your expectations of this course. three keywords about yourself Introduce yourself according to what you\u2019ve written down to your group in the break-out rooms.","title":"Introduction"},{"location":"day1/intro/#material","text":"Download the presentation","title":"Material"},{"location":"day1/intro/#ice-breaker-and-expectations","text":"30 minutes Write in the Google doc: your expectations of this course. three keywords about yourself Introduce yourself according to what you\u2019ve written down to your group in the break-out rooms.","title":"Ice-breaker and expectations"},{"location":"day1/quality_control/","text":"Material Download the presentation fastqc command line documentation trimmomatic manual Unix command line E-utilities documentation Exercises 1. Download and evaluate an E. coli dataset 30 minutes Exercise: Create a directory called workdir in your home directory and make the directory your current directory. If working with Docker If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd ~ mkdir workdir cd workdir Check out the dataset at SRA . Exercise: Browse around the SRA entry and answer these questions: A. Is the dataset paired-end or single end? B. Which instrument was used for sequencing? C. What is the read length? D. How many reads do we have? Answers A. paired-end B. Illumina MiSeq C. 2 x 252 bp D. 400596 Make a directory reads in ~/workdir and download the reads from the SRA database using prefetch and fastq-dump from SRA-Tools into the reads directory: mkdir reads cd reads prefetch SRR519926 fastq-dump --split-files SRR519926 Exercise: Check whether the download was successful by counting the number of reads in the fastq files and compare it to the SRA entry. Tip A read in a fastq file consists of four lines (more on that at file types ). Use Google to figure out how to count the number of reads in a fastq file. Answer e.g. from this thread on Biostars: ## forward read echo $( cat SRR519926_1.fastq | wc -l ) /4 | bc ## reverse read echo $( cat SRR519926_2.fastq | wc -l ) /4 | bc 2. Run fastqc 20 minutes Exercise: Run fastqc on the fastq files. Tip fastqc accepts multiple files as input, so you can use a wildcard to run fastqc on all the files in one line of code. Use it like this: *.fastq . Answer fastqc *.fastq Exercise: Download the html files to your local computer, and view the results. How is the quality? Where are the problems? Answer There seems to be: Low quality towards the 3\u2019 end (per base sequence quality) Full sequence reads with low quality (per sequence quality scores) Adapters in the sequences (adapter content) We can probably fix most of these issues by trimming. 3. Trim the reads 20 minutes We will use trimmomatic for trimming low quality and spurious bases from our reads. For paired-end data it generates four different trimmed fastq files. If one of the paired-end reads doesn\u2019t meet the quality thresholds, it will be discarded, but the other read might be kept. Therefore, trimmomatic outputs contains files with unpaired reads as well. Usually those files are very small compared to the paired reads, and are often ignored for downstream analyses. Trimmomatic syntax is rather complicated and different from most tools. Refer to the manual if you want to go deeper into this. Exercise: The script below will trim the sequence reads in a sensible manner. Execute the script to trim the data (note that the script is slightly different if you\u2019re working in the docker container): AWS ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data READS_DIR = ~/workdir/reads ADAPTERS = /opt/miniconda3/pkgs/trimmomatic-0.39-1/share/trimmomatic/adapters/TruSeq3-PE.fa mkdir $TRIMMED_DIR trimmomatic \\ PE \\ -threads 1 \\ -phred33 \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_2.fastq \\ ILLUMINACLIP: $ADAPTERS :2:30:10 \\ SLIDINGWINDOW:4:5 \\ LEADING:5 \\ TRAILING:5 \\ MINLEN:25 Docker ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data READS_DIR = ~/workdir/reads ADAPTERS = /opt/conda/pkgs/trimmomatic-0.39-1/share/trimmomatic/adapters/TruSeq3-PE.fa mkdir $TRIMMED_DIR trimmomatic \\ PE \\ -threads 1 \\ -phred33 \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_2.fastq \\ ILLUMINACLIP: $ADAPTERS :2:30:10 \\ SLIDINGWINDOW:4:5 \\ LEADING:5 \\ TRAILING:5 \\ MINLEN:25 The use of \\ In the script above you see that we\u2019re using \\ at the end of many lines. We use it to tell bash to ignore the newlines. If we would not do it, the trimmomatic command would become a very long line, and the script would become very difficult to read. It is in general good practice to put every option of a long command on a newline in your script and use \\ to ignore the newlines when executing. Exercise: Run fastqc on the trimmed fastq files and answer these questions: A. Has the quality improved? B. How many reads do we have left? C. There are more unpaired forward reads compared to reverse reads. Does this make sense? Answers Running fastqc : cd ~/workdir/trimmed_data fastqc paired_trimmed*.fastq A. Yes, low quality 3\u2019 end, per sequence quality and adapter sequences have improved. B. 264781 C. Again, Google to the rescue","title":"Quality control"},{"location":"day1/quality_control/#material","text":"Download the presentation fastqc command line documentation trimmomatic manual Unix command line E-utilities documentation","title":"Material"},{"location":"day1/quality_control/#exercises","text":"","title":"Exercises"},{"location":"day1/quality_control/#1-download-and-evaluate-an-e-coli-dataset","text":"30 minutes Exercise: Create a directory called workdir in your home directory and make the directory your current directory. If working with Docker If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd ~ mkdir workdir cd workdir Check out the dataset at SRA . Exercise: Browse around the SRA entry and answer these questions: A. Is the dataset paired-end or single end? B. Which instrument was used for sequencing? C. What is the read length? D. How many reads do we have? Answers A. paired-end B. Illumina MiSeq C. 2 x 252 bp D. 400596 Make a directory reads in ~/workdir and download the reads from the SRA database using prefetch and fastq-dump from SRA-Tools into the reads directory: mkdir reads cd reads prefetch SRR519926 fastq-dump --split-files SRR519926 Exercise: Check whether the download was successful by counting the number of reads in the fastq files and compare it to the SRA entry. Tip A read in a fastq file consists of four lines (more on that at file types ). Use Google to figure out how to count the number of reads in a fastq file. Answer e.g. from this thread on Biostars: ## forward read echo $( cat SRR519926_1.fastq | wc -l ) /4 | bc ## reverse read echo $( cat SRR519926_2.fastq | wc -l ) /4 | bc","title":"1. Download and evaluate an E. coli dataset"},{"location":"day1/quality_control/#2-run-fastqc","text":"20 minutes Exercise: Run fastqc on the fastq files. Tip fastqc accepts multiple files as input, so you can use a wildcard to run fastqc on all the files in one line of code. Use it like this: *.fastq . Answer fastqc *.fastq Exercise: Download the html files to your local computer, and view the results. How is the quality? Where are the problems? Answer There seems to be: Low quality towards the 3\u2019 end (per base sequence quality) Full sequence reads with low quality (per sequence quality scores) Adapters in the sequences (adapter content) We can probably fix most of these issues by trimming.","title":"2. Run fastqc"},{"location":"day1/quality_control/#3-trim-the-reads","text":"20 minutes We will use trimmomatic for trimming low quality and spurious bases from our reads. For paired-end data it generates four different trimmed fastq files. If one of the paired-end reads doesn\u2019t meet the quality thresholds, it will be discarded, but the other read might be kept. Therefore, trimmomatic outputs contains files with unpaired reads as well. Usually those files are very small compared to the paired reads, and are often ignored for downstream analyses. Trimmomatic syntax is rather complicated and different from most tools. Refer to the manual if you want to go deeper into this. Exercise: The script below will trim the sequence reads in a sensible manner. Execute the script to trim the data (note that the script is slightly different if you\u2019re working in the docker container): AWS ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data READS_DIR = ~/workdir/reads ADAPTERS = /opt/miniconda3/pkgs/trimmomatic-0.39-1/share/trimmomatic/adapters/TruSeq3-PE.fa mkdir $TRIMMED_DIR trimmomatic \\ PE \\ -threads 1 \\ -phred33 \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_2.fastq \\ ILLUMINACLIP: $ADAPTERS :2:30:10 \\ SLIDINGWINDOW:4:5 \\ LEADING:5 \\ TRAILING:5 \\ MINLEN:25 Docker ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data READS_DIR = ~/workdir/reads ADAPTERS = /opt/conda/pkgs/trimmomatic-0.39-1/share/trimmomatic/adapters/TruSeq3-PE.fa mkdir $TRIMMED_DIR trimmomatic \\ PE \\ -threads 1 \\ -phred33 \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_1.fastq \\ $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $TRIMMED_DIR /unpaired_trimmed_SRR519926_2.fastq \\ ILLUMINACLIP: $ADAPTERS :2:30:10 \\ SLIDINGWINDOW:4:5 \\ LEADING:5 \\ TRAILING:5 \\ MINLEN:25 The use of \\ In the script above you see that we\u2019re using \\ at the end of many lines. We use it to tell bash to ignore the newlines. If we would not do it, the trimmomatic command would become a very long line, and the script would become very difficult to read. It is in general good practice to put every option of a long command on a newline in your script and use \\ to ignore the newlines when executing. Exercise: Run fastqc on the trimmed fastq files and answer these questions: A. Has the quality improved? B. How many reads do we have left? C. There are more unpaired forward reads compared to reverse reads. Does this make sense? Answers Running fastqc : cd ~/workdir/trimmed_data fastqc paired_trimmed*.fastq A. Yes, low quality 3\u2019 end, per sequence quality and adapter sequences have improved. B. 264781 C. Again, Google to the rescue","title":"3. Trim the reads"},{"location":"day1/read_alignment/","text":"Material Download the presentation Unix command line E-utilities documentation bowtie2 manual Exercises 1. Prepare the reference sequence 10 minutes Retrieve the reference sequence using esearch and efetch : REFERENCE_DIR = ~/workdir/ref_genome/ mkdir $REFERENCE_DIR cd $REFERENCE_DIR esearch -db nuccore -query 'U00096' \\ | efetch -format fasta > ecoli-strK12-MG1655.fasta Exercise: Check out the documentation of bowtie2-build , and build a index for bowtie2 using default options. Answer bowtie2-build ecoli-strK12-MG1655.fasta ecoli-strK12-MG1655.fasta 2. Align the reads with bowtie2 20 minutes Exercise: Check out the bowtie2 manual here . We are going to align the sequences in paired-end mode. What are the options we\u2019ll minimally need? Answer According to the usage of bowtie2 : bowtie2 [ options ] * -x <bt2-idx> { -1 <m1> -2 <m2> | -U <r> | --interleaved <i> | --sra-acc <acc> | b <bam> } We\u2019ll need the options: -x to point to our index -1 and -2 to point to our forward and reverse reads Exercise: Try to understand what the script below does, and run it. ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data REFERENCE_DIR = ~/workdir/ref_genome/ ALIGNED_DIR = ~/workdir/alignment_output mkdir $ALIGNED_DIR bowtie2 \\ -x $REFERENCE_DIR /workdir-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ > $ALIGNED_DIR /SRR519926.sam We\u2019ll go deeper into alignment statistics tomorrow, but bowtie2 writes already some statistics to stdout. General alignment rates seem okay, but there are quite some non-concordant alignments. That doesn\u2019t sound good. Check out the explanation about concordance at the bowtie2 manual . Can you guess what the reason could be?","title":"Read alignment"},{"location":"day1/read_alignment/#material","text":"Download the presentation Unix command line E-utilities documentation bowtie2 manual","title":"Material"},{"location":"day1/read_alignment/#exercises","text":"","title":"Exercises"},{"location":"day1/read_alignment/#1-prepare-the-reference-sequence","text":"10 minutes Retrieve the reference sequence using esearch and efetch : REFERENCE_DIR = ~/workdir/ref_genome/ mkdir $REFERENCE_DIR cd $REFERENCE_DIR esearch -db nuccore -query 'U00096' \\ | efetch -format fasta > ecoli-strK12-MG1655.fasta Exercise: Check out the documentation of bowtie2-build , and build a index for bowtie2 using default options. Answer bowtie2-build ecoli-strK12-MG1655.fasta ecoli-strK12-MG1655.fasta","title":"1. Prepare the reference sequence"},{"location":"day1/read_alignment/#2-align-the-reads-with-bowtie2","text":"20 minutes Exercise: Check out the bowtie2 manual here . We are going to align the sequences in paired-end mode. What are the options we\u2019ll minimally need? Answer According to the usage of bowtie2 : bowtie2 [ options ] * -x <bt2-idx> { -1 <m1> -2 <m2> | -U <r> | --interleaved <i> | --sra-acc <acc> | b <bam> } We\u2019ll need the options: -x to point to our index -1 and -2 to point to our forward and reverse reads Exercise: Try to understand what the script below does, and run it. ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data REFERENCE_DIR = ~/workdir/ref_genome/ ALIGNED_DIR = ~/workdir/alignment_output mkdir $ALIGNED_DIR bowtie2 \\ -x $REFERENCE_DIR /workdir-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ > $ALIGNED_DIR /SRR519926.sam We\u2019ll go deeper into alignment statistics tomorrow, but bowtie2 writes already some statistics to stdout. General alignment rates seem okay, but there are quite some non-concordant alignments. That doesn\u2019t sound good. Check out the explanation about concordance at the bowtie2 manual . Can you guess what the reason could be?","title":"2. Align the reads with bowtie2"},{"location":"day1/sequencing_technologies/","text":"Material Download the presentation Illumina sequencing by synthesis on YouTube NEBnext library preparation poster","title":"Sequencing technologies"},{"location":"day1/sequencing_technologies/#material","text":"Download the presentation Illumina sequencing by synthesis on YouTube NEBnext library preparation poster","title":"Material"},{"location":"day1/server_login/","text":"Material In this part we will set up your computer to work on the remote AWS server or with Docker (choose Docker if you are doing this course independently). mac OS/Linux You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Before you do this part, you should have installed FileZilla and Atom. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations. Video tutorials Below you can find video tutorials to set up FileZilla and atom to edit and/or transfer remote files. Atom Atom is a versatile text editor for all major operating systems. For this course, it\u2019s the recommended script editor for Linux and Mac OS users. With the third-party package ftp-remote-edit , you can remotely edit scripts. The video tutorial explains how to set it up. FileZilla Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . The video tutorial explains how to set it up. Windows You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Before you do this part, you should have installed FileZilla and MobaXterm. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations. Video tutorials Below you can find video tutorials to set up FileZilla, atom and MobaXterm to edit and/or transfer remote files. MobaXterm MobaXterm is an SSH client for Windows. Use this to connect to the remote host and edit remote scripts if you\u2019re on Windows. The video tutorial explains how to set it up. FileZilla Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . The video tutorial explains how to set it up. Docker Instructions to install docker here . Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. Set up docker container In the video below there\u2019s a tutorial on how to set up a docker container for this course. Exercises 1. First login mac OS/Linux Login to AWS EC2 remote server Use the video tutorials and the information below to log in and set up a remote script editor. Open a terminal and login like this: ssh -i path/to/key/key_ [ USERNAME ] .pem [ USERNAME ] @ [ AWS_IP ] Warning change path/to/key to the actual path where you have put the key file. Setup your favourite editor to work remotely To directly initiate and modify scripts on the remote server you can use the Atom plugin ftp-remote-edit In general, setup the connection to the server with the following details: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file Tutorials are found above in the video tutorial to set up Atom . Initiate conda To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash To load the environment with the required software packages, run: conda activate ngs Activating the environment You will need to activate the ngs environment each time you login. Windows Login to AWS EC2 remote server Use the video tutorials and the information below to log in and set up a remote script editor. If you are using MobaXterm on windows, you will automatically login to the remote server once you\u2019ve started the SSH session. Follow the video tutorial on MobaXterm to set up an SSH session. These are the general settings you should take into account: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file Initiate conda To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash To load the environment with the required software packages, run: conda activate ngs Activating the environment You will need to activate the ngs environment each time you login. Docker Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. Use the video tutorial in combination with the commands below to set up the Docker container. A command to run the environment required for this course looks like this (in a terminal or powershell): Mac OS/Linux terminal docker run \\ -v /full/path/to/local/workdir:/root/workdir \\ -i -t \\ geertvangeest/ngs-intro \\ /bin/bash Windows powershell docker run ` -v C : \\ Users \\ myusername : / root / workdir ` -i -t ` geertvangeest / ngs-intro ` / bin / bash The option -v mounts a local directory in your computer to the directory /root/workdir in the docker container. In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. edit scripts and visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The options -i and -t let\u2019s you approach the container interactively. Meaning that you can use the shell. The last bit, geertvangeest/ngs-intro is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. You can exit the shell with exit . Restarting the container After exiting, you can restart the container. Find the container name: docker container ls -a The name is e.g. adoring_bell . To restart run: docker start adoring_bell docker attach adoring_bell If you have additional installations, and you want to keep them, you can save the image with: docker commit adoring_bell my-image Use conda If you are in the container with shell, you can load the environment with the required software packages: conda activate ngs Activating the environment You will need to activate the ngs environment each time you login. 2. A UNIX command line interface (CLI) refresher Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory. Make a new directory Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts File permissions Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer You can use your remote script editor to edit your script. Otherwise you can use nano to edit it: nano new_script.sh The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here . Redirection: > and | In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory. Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l Variables Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE shell scripts Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l 3. Detaching a job On this server, there is no job scheduler, so everything is run directly from the command line. That means that if a process is running, the command line will be busy, and the job will be killed upon logout. To circumvent this, there are several methods to \u2018detach\u2019 the screen or prevent a \u2018hangup signal\u2019 of a job runnig in the background that will terminate your running job. The software screen or tmux can be used to detach your screen, and all messages to stderr or stdout (if not redirected) will be printed to the (detached) console. Use those if you\u2019re comfortable with them. Another, more basic, program to prevent the \u2018hangup signal\u2019 is nohup . Use it like so: nohup [ YOUR COMMAND ] & Note Don\u2019t forget the & after the command. This symbol let\u2019s the process run in the background. So, for running e.g. a shell script this would be: nohup script.sh & Anything written to stdout or stderr will be written to the file nohup.out in your current working directory. Don\u2019t change your script while running nohup runs through your script line-by-line and reads it from disk. If you change your script while running it, it will run the new lines. Generate a script that waits for 120 seconds (use sleep ) and prints I'm done! to stdout if it\u2019s done. Answer Script called wait.sh : #!/usr/bin/env bash sleep 120 echo \"I'm done!\" Run this script in the background without a hangup signal (so, by using nohup ), logout, and login again, and see if it\u2019s still running with ps x . Answer nohup wait.sh & Remember the PID, logout and login (within 120 seconds.. ) ps x","title":"Setup + UNIX refresher"},{"location":"day1/server_login/#material","text":"In this part we will set up your computer to work on the remote AWS server or with Docker (choose Docker if you are doing this course independently). mac OS/Linux You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Before you do this part, you should have installed FileZilla and Atom. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations.","title":"Material"},{"location":"day1/server_login/#video-tutorials","text":"Below you can find video tutorials to set up FileZilla and atom to edit and/or transfer remote files.","title":"Video tutorials"},{"location":"day1/server_login/#atom","text":"Atom is a versatile text editor for all major operating systems. For this course, it\u2019s the recommended script editor for Linux and Mac OS users. With the third-party package ftp-remote-edit , you can remotely edit scripts. The video tutorial explains how to set it up.","title":"Atom"},{"location":"day1/server_login/#filezilla","text":"Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . The video tutorial explains how to set it up. Windows You have received an e-mail shortly before the workshop with a key, username and IP address to login on a cloud server. Before you do this part, you should have installed FileZilla and MobaXterm. Great power comes with great responsibility The cloud server is a temporary instance for this workshop only. Although the computational resources should be more than enough, it\u2019s a basic Ubuntu server, and there are no hard limits on memory or CPU usage. Take therefore into account that great power comes with great responsibility. Overloading it can result in a reboot, cancelling all running calculations.","title":"FileZilla"},{"location":"day1/server_login/#video-tutorials_1","text":"Below you can find video tutorials to set up FileZilla, atom and MobaXterm to edit and/or transfer remote files.","title":"Video tutorials"},{"location":"day1/server_login/#mobaxterm","text":"MobaXterm is an SSH client for Windows. Use this to connect to the remote host and edit remote scripts if you\u2019re on Windows. The video tutorial explains how to set it up.","title":"MobaXterm"},{"location":"day1/server_login/#filezilla_1","text":"Many results come in an image (e.g. .png , .jpg ) or html format. These can not be viewed directly from the server. Also, for this course, files loaded in IGV need to be on your local computer. You can easily transfer files between your local PC and the remote host with FileZilla . The video tutorial explains how to set it up. Docker Instructions to install docker here . Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10.","title":"FileZilla"},{"location":"day1/server_login/#set-up-docker-container","text":"In the video below there\u2019s a tutorial on how to set up a docker container for this course.","title":"Set up docker container"},{"location":"day1/server_login/#exercises","text":"","title":"Exercises"},{"location":"day1/server_login/#1-first-login","text":"mac OS/Linux","title":"1. First login"},{"location":"day1/server_login/#login-to-aws-ec2-remote-server","text":"Use the video tutorials and the information below to log in and set up a remote script editor. Open a terminal and login like this: ssh -i path/to/key/key_ [ USERNAME ] .pem [ USERNAME ] @ [ AWS_IP ] Warning change path/to/key to the actual path where you have put the key file.","title":"Login to AWS EC2 remote server"},{"location":"day1/server_login/#setup-your-favourite-editor-to-work-remotely","text":"To directly initiate and modify scripts on the remote server you can use the Atom plugin ftp-remote-edit In general, setup the connection to the server with the following details: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file Tutorials are found above in the video tutorial to set up Atom .","title":"Setup your favourite editor to work remotely"},{"location":"day1/server_login/#initiate-conda","text":"To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash To load the environment with the required software packages, run: conda activate ngs Activating the environment You will need to activate the ngs environment each time you login. Windows","title":"Initiate conda"},{"location":"day1/server_login/#login-to-aws-ec2-remote-server_1","text":"Use the video tutorials and the information below to log in and set up a remote script editor. If you are using MobaXterm on windows, you will automatically login to the remote server once you\u2019ve started the SSH session. Follow the video tutorial on MobaXterm to set up an SSH session. These are the general settings you should take into account: protocol: sftp username: your username hostname: server IP port: 22 authentication/logon type: path to private key file","title":"Login to AWS EC2 remote server"},{"location":"day1/server_login/#initiate-conda_1","text":"To make use of the pre-installed software with conda, we need to initiate it first. Login to the server and run: /opt/miniconda3/bin/conda init exec bash To load the environment with the required software packages, run: conda activate ngs Activating the environment You will need to activate the ngs environment each time you login. Docker Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. Use the video tutorial in combination with the commands below to set up the Docker container. A command to run the environment required for this course looks like this (in a terminal or powershell): Mac OS/Linux terminal docker run \\ -v /full/path/to/local/workdir:/root/workdir \\ -i -t \\ geertvangeest/ngs-intro \\ /bin/bash Windows powershell docker run ` -v C : \\ Users \\ myusername : / root / workdir ` -i -t ` geertvangeest / ngs-intro ` / bin / bash The option -v mounts a local directory in your computer to the directory /root/workdir in the docker container. In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. edit scripts and visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The options -i and -t let\u2019s you approach the container interactively. Meaning that you can use the shell. The last bit, geertvangeest/ngs-intro is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. You can exit the shell with exit .","title":"Initiate conda"},{"location":"day1/server_login/#restarting-the-container","text":"After exiting, you can restart the container. Find the container name: docker container ls -a The name is e.g. adoring_bell . To restart run: docker start adoring_bell docker attach adoring_bell If you have additional installations, and you want to keep them, you can save the image with: docker commit adoring_bell my-image","title":"Restarting the container"},{"location":"day1/server_login/#use-conda","text":"If you are in the container with shell, you can load the environment with the required software packages: conda activate ngs Activating the environment You will need to activate the ngs environment each time you login.","title":"Use conda"},{"location":"day1/server_login/#2-a-unix-command-line-interface-cli-refresher","text":"Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory.","title":"2. A UNIX command line interface (CLI) refresher"},{"location":"day1/server_login/#make-a-new-directory","text":"Login to the server and use the command line to make a directory called workdir . If working with Docker If your are working with docker you are a root user. This means that your \u201chome\u201d directory is the root directory, i.e. /root , and not /home/username . If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts","title":"Make a new directory"},{"location":"day1/server_login/#file-permissions","text":"Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer You can use your remote script editor to edit your script. Otherwise you can use nano to edit it: nano new_script.sh The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here .","title":"File permissions"},{"location":"day1/server_login/#redirection-and","text":"In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory. Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l","title":"Redirection: &gt; and |"},{"location":"day1/server_login/#variables","text":"Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE","title":"Variables"},{"location":"day1/server_login/#shell-scripts","text":"Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l","title":"shell scripts"},{"location":"day1/server_login/#3-detaching-a-job","text":"On this server, there is no job scheduler, so everything is run directly from the command line. That means that if a process is running, the command line will be busy, and the job will be killed upon logout. To circumvent this, there are several methods to \u2018detach\u2019 the screen or prevent a \u2018hangup signal\u2019 of a job runnig in the background that will terminate your running job. The software screen or tmux can be used to detach your screen, and all messages to stderr or stdout (if not redirected) will be printed to the (detached) console. Use those if you\u2019re comfortable with them. Another, more basic, program to prevent the \u2018hangup signal\u2019 is nohup . Use it like so: nohup [ YOUR COMMAND ] & Note Don\u2019t forget the & after the command. This symbol let\u2019s the process run in the background. So, for running e.g. a shell script this would be: nohup script.sh & Anything written to stdout or stderr will be written to the file nohup.out in your current working directory. Don\u2019t change your script while running nohup runs through your script line-by-line and reads it from disk. If you change your script while running it, it will run the new lines. Generate a script that waits for 120 seconds (use sleep ) and prints I'm done! to stdout if it\u2019s done. Answer Script called wait.sh : #!/usr/bin/env bash sleep 120 echo \"I'm done!\" Run this script in the background without a hangup signal (so, by using nohup ), logout, and login again, and see if it\u2019s still running with ps x . Answer nohup wait.sh & Remember the PID, logout and login (within 120 seconds.. ) ps x","title":"3. Detaching a job"},{"location":"day2/file_types/","text":"Material Download the presentation File definition websites: FASTQ (wikipedia) GFF (ensembl) VCF (Wikipedia) SAM: Wikipedia samtools Zhuyi Xue","title":"File types"},{"location":"day2/file_types/#material","text":"Download the presentation File definition websites: FASTQ (wikipedia) GFF (ensembl) VCF (Wikipedia) SAM: Wikipedia samtools Zhuyi Xue","title":"Material"},{"location":"day2/group_work/","text":"The last part of this course will consist of project-based-learning. This means that you will work in groups on a single question. We will split up into groups of five people. If working with Docker If you are working with Docker, I assume you are working independently and therefore can not work in a group. However, you can test your skills with these real biological datasets. Realize that the datasets and calculations are (much) bigger compared to the exercises, so check if your computer is up for it. You\u2019ll probably need around 4 cores, 16G of RAM and 50G of harddisk. If online If the course takes place online, we will use break-out rooms to communicate within groups. Please stay in the break-out room during the day, also if you are working individually. Roles & organisation Project based learning is about learning by doing, but also about peer instruction . This means that you will be both a learner and a teacher. There will be differences in levels among participants, but because of that, some will learn efficiently from people that have just learned, and others will teach and increase their understanding. Each project has tasks and questions . By performing the tasks, you should be able to answer the questions. At the start of the project, make sure that each of you gets a task assigned. You should consider the tasks and questions as a guidance. If interesting questions pop up during the project, you are encouraged to work on those. Also, you don\u2019t have to perform all the tasks and answer all the questions. In the afternoon of day 2, you will divide the initial tasks, and start on the project. On day 3, you can work on the project in the morning and in the first part of the afternoon. We will conclude the projects with a 10-minute presentation of each group. Project 1: Short-read RNA-seq of mice. Aim: Compare hisat2 (splice-aware) with bwa mem (splice unaware) while aligning a mouse RNA-seq dataset. In this project you will be working with data from: Singhania A, Graham CM, Gabry\u0161ov\u00e1 L, Moreira-Teixeira L, Stavropoulos E, Pitt JM, et al (2019). Transcriptional profiling unveils type I and II interferon networks in blood and tissues across diseases . Nat Commun. 10:1\u201321. https://doi.org/10.1038/s41467-019-10601-6 Here\u2019s the BioProject page . Download the mouse reference genome like this: ftp://ftp.ensembl.org/pub/release-101/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa.gz Tasks: Check out the BioProject, and download two samples that interest you. Do a QC on the data with fastqc Check which options to use, and run bwa-mem Check which options to use, and run hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV Compare different samples in read quality, alignment rates, depth, etc. Run featurecounts on both alignments Compare the count matrices in R or python Questions: What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run e.g. featureCounts ). Downloading from SRA prefetch [ SRR number ] fastq-dump --split-files --gzip [ SRR number ] Example code hisat2 Everything in between <> should be replaced with specific arguments hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <foward_reads.fastq.gz> \\ -2 <reverse_reads.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> Example code bwa mem bwa index <reference_sequence_fasta> bwa mem \\ <index_basename> \\ <forward_reads.fastq.gz> \\ <reverse_reads.fastq.gz> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> More resources Need e.g. a gtf file? Here\u2019s the ensembl page Spliced alignments Have a look at IGV on a particular gene, e.g. Nbr1 Project 2: Short-read RNA-seq data of Arabidopsis thaliana grown in space Aim: Compare hisat2 (splice-aware) with bowtie2 (splice unaware) while aligning an Arabidopsis RNA-seq dataset. The analysis of this dataset is reported in this paper: Vandenbrink JP, Herranz R, Poehlman WL, Alex Feltus F, Villacampa A, Ciska M, et al. (2019) RNA-seq analyses of Arabidopsis thaliana seedlings after exposure to blue-light phototropic stimuli in microgravity . Am J Bot. 106:1466\u201376. Reads can be found on the NASA repository here . You can download data with wget . Here is an example for downloading the forward and reverse reads for sample 131: wget -O sample_131_R1.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R1_001.fastq.gz?version = 1 wget -O sample_131_R2.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R2_001.fastq.gz?version = 1 Use of -O The name of the file is very long we use the option -O here to give it a shorter name. Download the reference genome sequence like this: wget ftp://ftp.ensemblgenomes.org/pub/plants/release-48/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz Tasks: Check out the BioProject, and download two samples that interest you. Do a QC on the data with fastqc Check which options to use, and run bwa-mem Check which options to use, and run hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV Compare different samples in read quality, alignment rates, depth, etc. Run featurecounts on both alignments Compare the count matrices in R or python Questions: What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run e.g. featureCounts ). Example code hisat2 Everything in between <> should be replaced with specific arguments hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <mate1.fastq.gz> \\ -2 <mate2.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> More resources Need e.g. a gtf file? Here\u2019s the ensembl page Project 3: Long-read genome sequencing Aim : Align long reads from RNA-seq data to a reference genome. In this project, you will be working with data from: Clark, M. B. et al (2020). Long-read sequencing reveals the complex splicing profile of the psychiatric risk gene CACNA1C in human brain . Molecular Psychiatry, 25(1), 37\u201347. https://doi.org/10.1038/s41380-019-0583-1 . Here you can find the BioProject page . It is Oxford Nanopore Technology sequencing data of amplicons of the gene CACNA1C. It is primarily used to discover new splice variants. In this project, we will align a few of the samples to the reference genome, and assess the quality of reads and the alignment. Download the human reference genome like this: wget ftp://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz Tasks: Check out the BioProject, and download two samples that interest you. Perform QC with fastqc Perform QC with NanoPlot Align with minimap2 with default parameters Figure how you should set parameters -x and -G Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare different samples in read quality, alignment rates, depth, etc. Bonus see if you can identify different splice variants using FLAIR (see hints below). Questions: Have a look at the quality report. What are the average read lengths? Is that expected? What is the average read quality? What kind of accuracy would you expect? Note any differences between fastqc and NanoPlot ? How is that compared to the publication? Check out the options -x and -G of minimap2 . Are the defaults appropriate? You might consider using -x map-ont or -x splice . Do you see differences in the alignment in e.g. IGV? How are spliced alignments stored in the SAM file with the different settings of -x ? How deep is the gene sequenced? Downloading from SRA prefetch [ SRR number ] fastq-dump --gzip [ SRR number ] Accuracy from quality scores Find the equation to calculate error probability from quality score on Wikipedia . Comparing fastqc and Nanoplot For comparing fastqc and NanoPlot , check out this blog of the author of NanoPlot, and this thread . Running minimap2 Here\u2019s an example command for minimap2 : minimap2 \\ -a \\ -x [ PARAMETER ] \\ -G [ PARAMETER ] \\ [ REFERENCE ] .fa \\ [ FASTQFILE ] .fastq.gz \\ | samtools sort \\ | samtools view -bh > [ OUTPUT ] .bam Intron sizes Check out the the intron sizes of CACNA1C in e.g. IGV or UCSC genome browser. How does that relate to the parameter -G ? More resources Need e.g. a gtf file? Here\u2019s the ensembl page Running FLAIR FLAIR is a set of python scripts that can be used to identify and quantify (new) isoforms based on alignment files of long-read sequencing data. You can basically follow the pipeline as described here . To use FLAIR first clone the git repository, and activate the (pre-configured) conda environment: cd git clone https://github.com/BrooksLabUCSC/flair.git After that, generate a FLAIR working directory and convert your .bam alignment file to bed12 format. mkdir ~/flair_output python3 ~/flair/bin/bam2Bed12.py \\ -i alignment.bam \\ > alignment.bed12 Generate (and run) a shell script to run the modules flair.py correct , flair.py collapse and flair.py quantify . To do this, carefully follow the manual at https://github.com/BrooksLabUCSC/flair. Structure and document your script(s), so you can easily re-run the analysis. Files you will need are: Reference genome (chromosome 12 only): /data/references/GRCh38.p13.chr12.fa GTF: /data/references/Homo_sapiens.GRCh38.100.gtf Reads manifest: /data/reads/lrrnaseq/batch_combined/reads_manifest.tsv","title":"Group work - organisation"},{"location":"day2/group_work/#roles-organisation","text":"Project based learning is about learning by doing, but also about peer instruction . This means that you will be both a learner and a teacher. There will be differences in levels among participants, but because of that, some will learn efficiently from people that have just learned, and others will teach and increase their understanding. Each project has tasks and questions . By performing the tasks, you should be able to answer the questions. At the start of the project, make sure that each of you gets a task assigned. You should consider the tasks and questions as a guidance. If interesting questions pop up during the project, you are encouraged to work on those. Also, you don\u2019t have to perform all the tasks and answer all the questions. In the afternoon of day 2, you will divide the initial tasks, and start on the project. On day 3, you can work on the project in the morning and in the first part of the afternoon. We will conclude the projects with a 10-minute presentation of each group.","title":"Roles &amp; organisation"},{"location":"day2/group_work/#project-1-short-read-rna-seq-of-mice","text":"Aim: Compare hisat2 (splice-aware) with bwa mem (splice unaware) while aligning a mouse RNA-seq dataset. In this project you will be working with data from: Singhania A, Graham CM, Gabry\u0161ov\u00e1 L, Moreira-Teixeira L, Stavropoulos E, Pitt JM, et al (2019). Transcriptional profiling unveils type I and II interferon networks in blood and tissues across diseases . Nat Commun. 10:1\u201321. https://doi.org/10.1038/s41467-019-10601-6 Here\u2019s the BioProject page . Download the mouse reference genome like this: ftp://ftp.ensembl.org/pub/release-101/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.primary_assembly.fa.gz","title":" Project 1: Short-read RNA-seq of mice."},{"location":"day2/group_work/#tasks","text":"Check out the BioProject, and download two samples that interest you. Do a QC on the data with fastqc Check which options to use, and run bwa-mem Check which options to use, and run hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV Compare different samples in read quality, alignment rates, depth, etc. Run featurecounts on both alignments Compare the count matrices in R or python","title":"Tasks:"},{"location":"day2/group_work/#questions","text":"What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run e.g. featureCounts ). Downloading from SRA prefetch [ SRR number ] fastq-dump --split-files --gzip [ SRR number ] Example code hisat2 Everything in between <> should be replaced with specific arguments hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <foward_reads.fastq.gz> \\ -2 <reverse_reads.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> Example code bwa mem bwa index <reference_sequence_fasta> bwa mem \\ <index_basename> \\ <forward_reads.fastq.gz> \\ <reverse_reads.fastq.gz> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> More resources Need e.g. a gtf file? Here\u2019s the ensembl page Spliced alignments Have a look at IGV on a particular gene, e.g. Nbr1","title":"Questions:"},{"location":"day2/group_work/#project-2-short-read-rna-seq-data-of-arabidopsis-thaliana-grown-in-space","text":"Aim: Compare hisat2 (splice-aware) with bowtie2 (splice unaware) while aligning an Arabidopsis RNA-seq dataset. The analysis of this dataset is reported in this paper: Vandenbrink JP, Herranz R, Poehlman WL, Alex Feltus F, Villacampa A, Ciska M, et al. (2019) RNA-seq analyses of Arabidopsis thaliana seedlings after exposure to blue-light phototropic stimuli in microgravity . Am J Bot. 106:1466\u201376. Reads can be found on the NASA repository here . You can download data with wget . Here is an example for downloading the forward and reverse reads for sample 131: wget -O sample_131_R1.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R1_001.fastq.gz?version = 1 wget -O sample_131_R2.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R2_001.fastq.gz?version = 1 Use of -O The name of the file is very long we use the option -O here to give it a shorter name. Download the reference genome sequence like this: wget ftp://ftp.ensemblgenomes.org/pub/plants/release-48/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz","title":" Project 2: Short-read RNA-seq data of Arabidopsis thaliana grown in space"},{"location":"day2/group_work/#tasks_1","text":"Check out the BioProject, and download two samples that interest you. Do a QC on the data with fastqc Check which options to use, and run bwa-mem Check which options to use, and run hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV Compare different samples in read quality, alignment rates, depth, etc. Run featurecounts on both alignments Compare the count matrices in R or python","title":"Tasks:"},{"location":"day2/group_work/#questions_1","text":"What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run e.g. featureCounts ). Example code hisat2 Everything in between <> should be replaced with specific arguments hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <mate1.fastq.gz> \\ -2 <mate2.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> More resources Need e.g. a gtf file? Here\u2019s the ensembl page","title":"Questions:"},{"location":"day2/group_work/#project-3-long-read-genome-sequencing","text":"Aim : Align long reads from RNA-seq data to a reference genome. In this project, you will be working with data from: Clark, M. B. et al (2020). Long-read sequencing reveals the complex splicing profile of the psychiatric risk gene CACNA1C in human brain . Molecular Psychiatry, 25(1), 37\u201347. https://doi.org/10.1038/s41380-019-0583-1 . Here you can find the BioProject page . It is Oxford Nanopore Technology sequencing data of amplicons of the gene CACNA1C. It is primarily used to discover new splice variants. In this project, we will align a few of the samples to the reference genome, and assess the quality of reads and the alignment. Download the human reference genome like this: wget ftp://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz","title":" Project 3: Long-read genome sequencing"},{"location":"day2/group_work/#tasks_2","text":"Check out the BioProject, and download two samples that interest you. Perform QC with fastqc Perform QC with NanoPlot Align with minimap2 with default parameters Figure how you should set parameters -x and -G Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare different samples in read quality, alignment rates, depth, etc. Bonus see if you can identify different splice variants using FLAIR (see hints below).","title":"Tasks:"},{"location":"day2/group_work/#questions_2","text":"Have a look at the quality report. What are the average read lengths? Is that expected? What is the average read quality? What kind of accuracy would you expect? Note any differences between fastqc and NanoPlot ? How is that compared to the publication? Check out the options -x and -G of minimap2 . Are the defaults appropriate? You might consider using -x map-ont or -x splice . Do you see differences in the alignment in e.g. IGV? How are spliced alignments stored in the SAM file with the different settings of -x ? How deep is the gene sequenced? Downloading from SRA prefetch [ SRR number ] fastq-dump --gzip [ SRR number ] Accuracy from quality scores Find the equation to calculate error probability from quality score on Wikipedia . Comparing fastqc and Nanoplot For comparing fastqc and NanoPlot , check out this blog of the author of NanoPlot, and this thread . Running minimap2 Here\u2019s an example command for minimap2 : minimap2 \\ -a \\ -x [ PARAMETER ] \\ -G [ PARAMETER ] \\ [ REFERENCE ] .fa \\ [ FASTQFILE ] .fastq.gz \\ | samtools sort \\ | samtools view -bh > [ OUTPUT ] .bam Intron sizes Check out the the intron sizes of CACNA1C in e.g. IGV or UCSC genome browser. How does that relate to the parameter -G ? More resources Need e.g. a gtf file? Here\u2019s the ensembl page Running FLAIR FLAIR is a set of python scripts that can be used to identify and quantify (new) isoforms based on alignment files of long-read sequencing data. You can basically follow the pipeline as described here . To use FLAIR first clone the git repository, and activate the (pre-configured) conda environment: cd git clone https://github.com/BrooksLabUCSC/flair.git After that, generate a FLAIR working directory and convert your .bam alignment file to bed12 format. mkdir ~/flair_output python3 ~/flair/bin/bam2Bed12.py \\ -i alignment.bam \\ > alignment.bed12 Generate (and run) a shell script to run the modules flair.py correct , flair.py collapse and flair.py quantify . To do this, carefully follow the manual at https://github.com/BrooksLabUCSC/flair. Structure and document your script(s), so you can easily re-run the analysis. Files you will need are: Reference genome (chromosome 12 only): /data/references/GRCh38.p13.chr12.fa GTF: /data/references/Homo_sapiens.GRCh38.100.gtf Reads manifest: /data/reads/lrrnaseq/batch_combined/reads_manifest.tsv","title":"Questions:"},{"location":"day2/igv_visualisation/","text":"Material The exercises below are partly based on this tutorial from the Griffith lab . Exercises 1. A first glance: the E. coli dataset Index the alignment that was filtered for the region between 2000 and 2500 kb: cd ~/workdir/alignment_output samtools index SRR519926.sorted.region.bam Download it together with it\u2019s index file ( SRR519926.sorted.region.bam.bai ) and the reference genome ( ecoli-strK12-MG1655.fasta ) to your desktop. If working with Docker If you are working with Docker, you can find the files in the working directory that you mounted to the docker container (with the -v option). So if you have used -v C:\\Users\\myusername\\ngs-course:/root/workdir , your files will be in C:\\Users\\myusername\\ngs-course . Load the genome ( .fasta ) into IGV: Genomes > Load Genome from File\u2026 Load the alignment file ( .bam ): File > Load from File\u2026 Zoom in into the region U00096.3:2046000-2048000. You can do this in two ways: With the search box Select the region in the location bar View the reads as pairs, by right click on the reads and select View as pairs Exercise: There are lot of reads that are coloured red. Why is that? Answer According to IGV , reads are coloured red if the insert size is larger than expected. As you remember, this dataset has a very large variation in insert size. Modify the popup text behaviour by clicking on the yellow balloon to Show Details on Click : Exercise: Click on one of the reads. What kind of information is there? Answer Most of the information from the SAM file. Colour the alignment by pair orientation by right clicking on the reads, and click Color alignments by > read strand . 2. HCC1143 data set For this part, we will be using publicly available Illumina sequence data generated for the HCC1143 cell line. The HCC1143 cell line was generated from a 52 year old caucasian woman with breast cancer. Sequence reads were aligned to version GRCh37 of the human reference genome. We will be working with subsets of aligned reads in the region: chromosome 21: 19,000,000 - 20,000,000. The BAM files containing these reads for the cancer cell line and the matched normal are: HCC1143.normal.21.19M-20M.bam HCC1143.normal.21.19M-20M.bam.bai A lot of model-organism genomes are built-in IGV. Select the human genome version hg19 from the drop down menu: Select File > Load from File\u2026 from the main menu and select the BAM file HCC1143.normal.21.19M-20M.bam using the file browser. This BAM file only contains data for a 1 Megabase region of chromosome 21. Let\u2019s navigate there to see what genes this region covers. To do so, navigate to chr21:19,000,000-20,000,000 . Navigate to the gene CHODL by typing it in the search box. Load the dbsnp annotations by clicking File > Load From Server\u2026 > Annotations > Variation and Repeats > dbSNP 1.4.7 Like you did with the gene (i.e. by typing it in the search box), navigate to SNP rs3827160 that is annotated in the loaded file. Click on the coverage track where the SNP is: Exercise: What is the sequence coverage for that base? And the percentage T? Answer The coverage is 62, and 25 reads (40%) T. Navigate to region chr21:19,800,320-19,818,162 Load repeat tracks by selecting File > Load from Server\u2026 from the main menu and then select Annotations > Variation and Repeats > Repeat Masker Note This might take a while to load. Right click in the alignment track and select Color alignments by > insert size and pair orientation Exercise: Why are some reads coloured white? What can be the cause of that? Answer The white coloured reads have a map quality of 0 (click on the read to find the mapping quality). The cause of that is a LINE repeat region called L1PA3. Navigate to region chr21:19,324,500-19,331,500 Right click in the main alignment track and select: Expanded View as pairs Color alignments by > insert size and pair orientation Sort alignments by > insert size Exercise: What is the insert size of the red flagged read pairs? Can you estimate the size of the deletion? Answer The insert size is about 2.8 kb. This includes the reads. The deletion should be about 2.5 - 2.6 kb.","title":"IGV and visualisation"},{"location":"day2/igv_visualisation/#material","text":"The exercises below are partly based on this tutorial from the Griffith lab .","title":"Material"},{"location":"day2/igv_visualisation/#exercises","text":"","title":"Exercises"},{"location":"day2/igv_visualisation/#1-a-first-glance-the-e-coli-dataset","text":"Index the alignment that was filtered for the region between 2000 and 2500 kb: cd ~/workdir/alignment_output samtools index SRR519926.sorted.region.bam Download it together with it\u2019s index file ( SRR519926.sorted.region.bam.bai ) and the reference genome ( ecoli-strK12-MG1655.fasta ) to your desktop. If working with Docker If you are working with Docker, you can find the files in the working directory that you mounted to the docker container (with the -v option). So if you have used -v C:\\Users\\myusername\\ngs-course:/root/workdir , your files will be in C:\\Users\\myusername\\ngs-course . Load the genome ( .fasta ) into IGV: Genomes > Load Genome from File\u2026 Load the alignment file ( .bam ): File > Load from File\u2026 Zoom in into the region U00096.3:2046000-2048000. You can do this in two ways: With the search box Select the region in the location bar View the reads as pairs, by right click on the reads and select View as pairs Exercise: There are lot of reads that are coloured red. Why is that? Answer According to IGV , reads are coloured red if the insert size is larger than expected. As you remember, this dataset has a very large variation in insert size. Modify the popup text behaviour by clicking on the yellow balloon to Show Details on Click : Exercise: Click on one of the reads. What kind of information is there? Answer Most of the information from the SAM file. Colour the alignment by pair orientation by right clicking on the reads, and click Color alignments by > read strand .","title":"1. A first glance: the E. coli dataset"},{"location":"day2/igv_visualisation/#2-hcc1143-data-set","text":"For this part, we will be using publicly available Illumina sequence data generated for the HCC1143 cell line. The HCC1143 cell line was generated from a 52 year old caucasian woman with breast cancer. Sequence reads were aligned to version GRCh37 of the human reference genome. We will be working with subsets of aligned reads in the region: chromosome 21: 19,000,000 - 20,000,000. The BAM files containing these reads for the cancer cell line and the matched normal are: HCC1143.normal.21.19M-20M.bam HCC1143.normal.21.19M-20M.bam.bai A lot of model-organism genomes are built-in IGV. Select the human genome version hg19 from the drop down menu: Select File > Load from File\u2026 from the main menu and select the BAM file HCC1143.normal.21.19M-20M.bam using the file browser. This BAM file only contains data for a 1 Megabase region of chromosome 21. Let\u2019s navigate there to see what genes this region covers. To do so, navigate to chr21:19,000,000-20,000,000 . Navigate to the gene CHODL by typing it in the search box. Load the dbsnp annotations by clicking File > Load From Server\u2026 > Annotations > Variation and Repeats > dbSNP 1.4.7 Like you did with the gene (i.e. by typing it in the search box), navigate to SNP rs3827160 that is annotated in the loaded file. Click on the coverage track where the SNP is: Exercise: What is the sequence coverage for that base? And the percentage T? Answer The coverage is 62, and 25 reads (40%) T. Navigate to region chr21:19,800,320-19,818,162 Load repeat tracks by selecting File > Load from Server\u2026 from the main menu and then select Annotations > Variation and Repeats > Repeat Masker Note This might take a while to load. Right click in the alignment track and select Color alignments by > insert size and pair orientation Exercise: Why are some reads coloured white? What can be the cause of that? Answer The white coloured reads have a map quality of 0 (click on the read to find the mapping quality). The cause of that is a LINE repeat region called L1PA3. Navigate to region chr21:19,324,500-19,331,500 Right click in the main alignment track and select: Expanded View as pairs Color alignments by > insert size and pair orientation Sort alignments by > insert size Exercise: What is the insert size of the red flagged read pairs? Can you estimate the size of the deletion? Answer The insert size is about 2.8 kb. This includes the reads. The deletion should be about 2.5 - 2.6 kb.","title":"2. HCC1143 data set"},{"location":"day2/samtools/","text":"Material samtools documentation Exercises 1. Alignment statistics 10 minutes Exercise: Check out the statistics of the E. coli alignment by using samtools flagstat . Find the documentation here . Anything that draws your attention? Answer Code: cd ~/workdir/alignment_output/ samtools flagstat SRR519926.sam resulting in: 529562 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 526159 + 0 mapped (99.36% : N/A) 529562 + 0 paired in sequencing 264781 + 0 read1 264781 + 0 read2 203576 + 0 properly paired (38.44% : N/A) 523484 + 0 with itself and mate mapped 2675 + 0 singletons (0.51% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Of the reads, 38.44% is properly paired. The rest isn\u2019t. Proper pairing is quite hard to interpret. It usually means that the 0x2 flag (each segment properly aligned according to the aligner) is false. In this case it means that the insert size is high for a lot of sequences. That is because the insert size distribution is very wide. You can find info on insert size distribution like this: samtools stats SRR519926.sam | grep ^SN | cut -f 2,3 Now look at insert size average and insert size standard deviation . You can see the standard deviation is higher than the average, suggesting a wide distribution. 2. Compression, sorting and indexing 20 minutes The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: Samtools writes to stdout By default, samtools writes it\u2019s output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh SRR519926.sam > SRR519926.bam By using ls -lh , you can find out that SRR519926.sam has a size of 223 Mb, while SRR519926.bam is only 67 Mb. To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools sort SRR519926.bam > SRR519926.sorted.bam samtools index SRR519926.sorted.bam 3. Filtering 30 minutes With samtools view you can easily filter your alignment file based on flags. One thing that might be sensible to do at some point is to filter out unmapped reads. Exercise: Check out the flag that you would need to filter for mapped reads. It\u2019s at page 7 of the SAM documentation . Answer You will need the 0x4 flag. Filtering against unmapped reads (leaving only mapped reads) with samtools view would look like this: samtools view -bh -F 0x4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam or: samtools view -bh -F 4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam Exercise: Write a command that outputs only the unmapped reads (so the opposite of the example). How many reads are in there? Is that the same as what we expect based on the output of samtools flagstat ? Tip Check out the -f and -c options of samtools view Answer Filter like this: samtools view -bh -f 0x4 SRR519926.sorted.bam > SRR519926.sorted.unmapped.bam Counting like this: samtools view -c SRR519926.sorted.unmapped.bam This should correspond to the output of samtools flagstat (529562 - 526159 = 3403) samtools view also enables you to filter alignments in a specific region. This can be convenient if you don\u2019t want to work with huge alignment files and if you\u2019re only interested in alignments in a particular region. Region filtering only works for sorted and indexed alignment files. Exercise: Filter our sorted and indexed BAM file for the region between 2000 and 2500 kb, and output it as a BAM file with a header. Tip: Specifying a region Our E. coli genome has only one chromosome, because only one line starts with > in the fasta file cd ~/workdir/ref_genome grep \">\" ecoli-strK12-MG1655.fasta gives: >U00096.3 Escherichia coli str. K-12 substr. MG1655, complete genome The part after the first space in the title is cut off for the alignment reference. So the code for specifying a region would be: U00096.3:START-END Answer cd ~/workdir/alignment_output samtools view -bh SRR519926.sorted.bam U00096.3:2000000-2500000 > SRR519926.sorted.region.bam 4. Redirection 20 minutes Samtools is easy to use in a pipe. In this case you can replace the input file with a - . For example, you can sort and compress the output of your alignment software in a pipe like this: my_alignment_command \\ | samtools sort - \\ | samtools view -bh - \\ > alignment.bam The use of - In the modern versions of samtools, the use of - is not needed for most cases, so without an input file it reads from stdin. However, if you\u2019re not sure, it\u2019s better to be safe than sorry. Exercise: Write a script that maps the reads with bowtie2 (see chapter 2 of read alignment ), sorts them, takes only the mapped reads, and outputs them as a BAM file with a header. Answer ##!/usr/bin/env bash TRIMMED_DIR=~/workdir/trimmed_data REFERENCE_DIR=~/workdir/ref_genome ALIGNED_DIR=~/workdir/alignment_output bowtie2 \\ -x $REFERENCE_DIR/ecoli-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR/paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR/paired_trimmed_SRR519926_2.fastq \\ | samtools sort - \\ | samtools view -F 0x4 -bh - \\ > $ALIGNED_DIR/SRR519926.sorted.mapped.frompipe.bam","title":"Samtools"},{"location":"day2/samtools/#material","text":"samtools documentation","title":"Material"},{"location":"day2/samtools/#exercises","text":"","title":"Exercises"},{"location":"day2/samtools/#1-alignment-statistics","text":"10 minutes Exercise: Check out the statistics of the E. coli alignment by using samtools flagstat . Find the documentation here . Anything that draws your attention? Answer Code: cd ~/workdir/alignment_output/ samtools flagstat SRR519926.sam resulting in: 529562 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 526159 + 0 mapped (99.36% : N/A) 529562 + 0 paired in sequencing 264781 + 0 read1 264781 + 0 read2 203576 + 0 properly paired (38.44% : N/A) 523484 + 0 with itself and mate mapped 2675 + 0 singletons (0.51% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Of the reads, 38.44% is properly paired. The rest isn\u2019t. Proper pairing is quite hard to interpret. It usually means that the 0x2 flag (each segment properly aligned according to the aligner) is false. In this case it means that the insert size is high for a lot of sequences. That is because the insert size distribution is very wide. You can find info on insert size distribution like this: samtools stats SRR519926.sam | grep ^SN | cut -f 2,3 Now look at insert size average and insert size standard deviation . You can see the standard deviation is higher than the average, suggesting a wide distribution.","title":"1. Alignment statistics"},{"location":"day2/samtools/#2-compression-sorting-and-indexing","text":"20 minutes The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: Samtools writes to stdout By default, samtools writes it\u2019s output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh SRR519926.sam > SRR519926.bam By using ls -lh , you can find out that SRR519926.sam has a size of 223 Mb, while SRR519926.bam is only 67 Mb. To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools sort SRR519926.bam > SRR519926.sorted.bam samtools index SRR519926.sorted.bam","title":"2. Compression, sorting and indexing"},{"location":"day2/samtools/#3-filtering","text":"30 minutes With samtools view you can easily filter your alignment file based on flags. One thing that might be sensible to do at some point is to filter out unmapped reads. Exercise: Check out the flag that you would need to filter for mapped reads. It\u2019s at page 7 of the SAM documentation . Answer You will need the 0x4 flag. Filtering against unmapped reads (leaving only mapped reads) with samtools view would look like this: samtools view -bh -F 0x4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam or: samtools view -bh -F 4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam Exercise: Write a command that outputs only the unmapped reads (so the opposite of the example). How many reads are in there? Is that the same as what we expect based on the output of samtools flagstat ? Tip Check out the -f and -c options of samtools view Answer Filter like this: samtools view -bh -f 0x4 SRR519926.sorted.bam > SRR519926.sorted.unmapped.bam Counting like this: samtools view -c SRR519926.sorted.unmapped.bam This should correspond to the output of samtools flagstat (529562 - 526159 = 3403) samtools view also enables you to filter alignments in a specific region. This can be convenient if you don\u2019t want to work with huge alignment files and if you\u2019re only interested in alignments in a particular region. Region filtering only works for sorted and indexed alignment files. Exercise: Filter our sorted and indexed BAM file for the region between 2000 and 2500 kb, and output it as a BAM file with a header. Tip: Specifying a region Our E. coli genome has only one chromosome, because only one line starts with > in the fasta file cd ~/workdir/ref_genome grep \">\" ecoli-strK12-MG1655.fasta gives: >U00096.3 Escherichia coli str. K-12 substr. MG1655, complete genome The part after the first space in the title is cut off for the alignment reference. So the code for specifying a region would be: U00096.3:START-END Answer cd ~/workdir/alignment_output samtools view -bh SRR519926.sorted.bam U00096.3:2000000-2500000 > SRR519926.sorted.region.bam","title":"3. Filtering"},{"location":"day2/samtools/#4-redirection","text":"20 minutes Samtools is easy to use in a pipe. In this case you can replace the input file with a - . For example, you can sort and compress the output of your alignment software in a pipe like this: my_alignment_command \\ | samtools sort - \\ | samtools view -bh - \\ > alignment.bam The use of - In the modern versions of samtools, the use of - is not needed for most cases, so without an input file it reads from stdin. However, if you\u2019re not sure, it\u2019s better to be safe than sorry. Exercise: Write a script that maps the reads with bowtie2 (see chapter 2 of read alignment ), sorts them, takes only the mapped reads, and outputs them as a BAM file with a header. Answer ##!/usr/bin/env bash TRIMMED_DIR=~/workdir/trimmed_data REFERENCE_DIR=~/workdir/ref_genome ALIGNED_DIR=~/workdir/alignment_output bowtie2 \\ -x $REFERENCE_DIR/ecoli-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR/paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR/paired_trimmed_SRR519926_2.fastq \\ | samtools sort - \\ | samtools view -F 0x4 -bh - \\ > $ALIGNED_DIR/SRR519926.sorted.mapped.frompipe.bam","title":"4. Redirection"}]}