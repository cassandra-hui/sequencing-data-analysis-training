{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"NGS - Quality control, Alignment, Visualisation This course can be done both enrolled (with a teacher) and independently (in your own time). Choose below what applies to you. Enrolled to the course Material This website Zoom meeting (through mail) Google doc (through mail) Slack channel Learning outcomes After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output Learning experiences This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only. Exercises Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different. Asking questions During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online). Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button: A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. If you are replying to a question, use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re really stuck and need specific tutor support, write the teachers or helpers personally. To summarise: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #q-and-a on slack Independently You can do this course completely independently without a teacher. To do the exercises, we will set things up locally with a Docker container. If there any issues, use the issues page on our github repository . Note It might take us a while to respond to issues. Therefore, first check if a similar issue already exists, and/or try to fix it yourself. There\u2019s a lot of documentation/fora/threads on the web! Learning outcomes After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output Exercises Each block has practical work involved. Some more than others. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Home"},{"location":"#ngs-quality-control-alignment-visualisation","text":"This course can be done both enrolled (with a teacher) and independently (in your own time). Choose below what applies to you. Enrolled to the course","title":"NGS - Quality control, Alignment, Visualisation"},{"location":"#material","text":"This website Zoom meeting (through mail) Google doc (through mail) Slack channel","title":"Material"},{"location":"#learning-outcomes","text":"After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output","title":"Learning outcomes"},{"location":"#learning-experiences","text":"This course will consist of lectures, exercises and polls. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.","title":"Learning experiences"},{"location":"#exercises","text":"Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"#asking-questions","text":"During lectures, you are encouraged to raise your hand if you have questions (if in-person), or use the Zoom functionality (if online). Find the buttons in the participants list (\u2018Participants\u2019 button): Alternatively, (depending on your zoom version or OS) use the \u2018Reactions\u2019 button: A main source of communication will be our slack channel . Ask background questions that interest you personally at #background . During the exercises, e.g. if you are stuck or don\u2019t understand what is going on, use the slack channel #q-and-a . This channel is not only meant for asking questions but also for answering questions of other participants. If you are replying to a question, use the \u201creply in thread\u201d option: The teacher will review the answers, and add/modify if necessary. If you\u2019re really stuck and need specific tutor support, write the teachers or helpers personally. To summarise: During lectures: raise hand/zoom functionality Personal interest questions: #background During exercises: #q-and-a on slack Independently You can do this course completely independently without a teacher. To do the exercises, we will set things up locally with a Docker container. If there any issues, use the issues page on our github repository . Note It might take us a while to respond to issues. Therefore, first check if a similar issue already exists, and/or try to fix it yourself. There\u2019s a lot of documentation/fora/threads on the web!","title":"Asking questions"},{"location":"#learning-outcomes_1","text":"After this course, you will be able to: Understand the basics of the different NGS technologies Perform quality control for better downstream analysis Align reads to a reference genome Visualize the output","title":"Learning outcomes"},{"location":"#exercises_1","text":"Each block has practical work involved. Some more than others. All answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.","title":"Exercises"},{"location":"course_schedule/","text":"Day 1 block start end subject introduction 9:00 AM 9:30 AM Introduction block 1 9:30 AM 10:30 AM Sequencing technologies 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Quality control 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Group work Day 2 block start end subject block 1 9:00 AM 10:30 AM Read alignment 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM File types 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Samtools 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Group work Day 3 block start end subject block 1 9:00 AM 10:30 PM IGV and visualisation 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Group work 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Group work 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Presentations","title":"Course schedule"},{"location":"course_schedule/#day-1","text":"block start end subject introduction 9:00 AM 9:30 AM Introduction block 1 9:30 AM 10:30 AM Sequencing technologies 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Server login + unix fresh up 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Quality control 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Group work","title":"Day 1"},{"location":"course_schedule/#day-2","text":"block start end subject block 1 9:00 AM 10:30 AM Read alignment 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM File types 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Samtools 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Group work","title":"Day 2"},{"location":"course_schedule/#day-3","text":"block start end subject block 1 9:00 AM 10:30 PM IGV and visualisation 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Group work 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Group work 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Presentations","title":"Day 3"},{"location":"group_work/","text":"The last part of this course will consist of project-based-learning. This means that you will work in groups on a single question. We will split up into groups of five people. If working with Docker If you are working with Docker, I assume you are working independently and therefore can not work in a group. However, you can test your skills with these real biological datasets. Realize that the datasets and calculations are (much) bigger compared to the exercises, so check if your computer is up for it. You\u2019ll probably need around 4 cores, 16G of RAM and 50G of harddisk. If online If the course takes place online, we will use break-out rooms to communicate within groups. Please stay in the break-out room during the day, also if you are working individually. Roles & organisation Project based learning is about learning by doing, but also about peer instruction . This means that you will be both a learner and a teacher. There will be differences in levels among participants, but because of that, some will learn efficiently from people that have just learned, and others will teach and increase their understanding. Each project has tasks and questions . By performing the tasks, you should be able to answer the questions. You should consider the tasks and questions as a guidance. If interesting questions pop up during the project, you are encouraged to work on those. Also, you don\u2019t have to perform all the tasks and answer all the questions. In the afternoon of day 1, you will start on the project. On day 3, you can work on the project in the morning and in the first part of the afternoon. We will conclude the projects with a 10-minute presentation of each group. Working directories Each group has access to a shared working directory. It is mounted in the root directory ( / ). Make a soft link in your home directory: cd ~ ln -s /group_work/<group name> ./ Now you can find your group directory at ~/<group name> . Use this to share files. Warning Do not remove the soft link with rm -r , this will delete the entire source directory. If you want to remove only the softlink, use rm (without -r ), or unlink . More info here . Project 1: Short-read RNA-seq data of Arabidopsis thaliana grown in space Aim: Compare hisat2 (splice-aware) with bowtie2 (splice unaware) while aligning an Arabidopsis RNA-seq dataset. The analysis of this dataset is reported in this paper: Vandenbrink JP, Herranz R, Poehlman WL, Alex Feltus F, Villacampa A, Ciska M, et al. (2019) RNA-seq analyses of Arabidopsis thaliana seedlings after exposure to blue-light phototropic stimuli in microgravity . Am J Bot. 106:1466\u201376. Reads can be found on the NASA repository here . You can download data with wget . Here is an example for downloading the forward and reverse reads for sample 131: wget -O sample_131_R1.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R1_001.fastq.gz?version = 1 wget -O sample_131_R2.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R2_001.fastq.gz?version = 1 Use of -O The name of the file is very long we use the option -O here to give it a shorter name. Download the reference genome sequence like this: wget ftp://ftp.ensemblgenomes.org/pub/plants/release-48/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz gunzip Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz You can download the gtf like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/Araport11_GTF_genes_transposons.Mar202021.noChr.gtf.gz gunzip Araport11_GTF_genes_transposons.Mar202021.noChr.gtf.gz Tasks: Check out the project page, and download one or two samples that interest you (download both the forward and reverse reads from the same sample). Do a QC on the data with fastqc Trim adapters and low quality bases with cutadapt (the adapter sequences are the same as in the exercises). Check which options to use, and align with bowtie2 Check which options to use, and align with hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV. For this, download only a part of the bam file (e.g. the region 1:22145-42561 ). Compare different samples in read quality, alignment rates, depth, etc. Run featureCounts on both alignments Compare the count matrices in R or python (Rstudio server is running on the same machine. Approach it with your credentials and username rstudio ) Questions: What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? (have a look at the CIGAR string) Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run featureCounts ). Run your processes on multiple cores! We are now doing computations on a full genome, with full transcriptomic data. This is quite a bit more than we have used during the exercises. Therefore, computations take longer. However, most tools support parallel processing, in which you can specify how many cores you want to use to run in parallel. Your environment contains four cores, so this is also the maximum number of processes you can specify. Below you can find the options used in each command to specify multi-core processing. command option bowtie2-build --threads hisat2-build --threads fastqc --threads cutadapt --cores bowtie2 --threads hisat2 --threads featureCounts -T Example code hisat2 and featureCounts Everything in between <> should be replaced with specific arguments. Here\u2019s an example for hisat2 : hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <foward_reads.fastq.gz> \\ -2 <reverse_reads.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> Example code featureCounts : featureCounts \\ -p \\ -T 2 \\ -a <annotations.gtf> \\ -o <output.counts.txt> \\ <bowtie2_alignment.bam> <hisat2_alignment.bam> Reading in the count data in R You can read in the count data table, and compare the log2 counts of the two aligners like this: cts <- read.delim ( 'project_work/project3/counts/counts.txt' , comment.char = '#' ) plot ( log2 ( cts $ ..alignments.SRR7822040.chr5.bt2.bam ), log2 ( cts $ ..alignments.SRR7822040.chr5.hs2.bam )) Project 2: Long-read genome sequencing Aim : Align long reads from RNA-seq data to a reference genome. In this project, you will be working with data from: Clark, M. B. et al (2020). Long-read sequencing reveals the complex splicing profile of the psychiatric risk gene CACNA1C in human brain . Molecular Psychiatry, 25(1), 37\u201347. https://doi.org/10.1038/s41380-019-0583-1 . Here you can find the BioProject page . It is Oxford Nanopore Technology sequencing data of amplicons of the gene CACNA1C. It is primarily used to discover new splice variants. In this project, we will align a few of the samples to the reference genome, and assess the quality of reads and the alignment. Download the human reference genome like this: wget ftp://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz Tasks: Check out the BioProject, and download two samples that interest you. Perform QC with fastqc Perform QC with NanoPlot Align with minimap2 with default parameters Figure how you should set parameters -x and -G Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare different samples in read quality, alignment rates, depth, etc. Questions: Have a look at the quality report. What are the average read lengths? Is that expected? What is the average read quality? What kind of accuracy would you expect? Note any differences between fastqc and NanoPlot ? How is that compared to the publication? Check out the options -x and -G of minimap2 . Are the defaults appropriate? You might consider using -x map-ont or -x splice . Do you see differences in the alignment in e.g. IGV? How are spliced alignments stored in the SAM file with the different settings of -x ? How deep is the gene sequenced? Do you already see evidence for splice variants in the alignments? Downloading from SRA prefetch [ SRR number ] fastq-dump --gzip [ SRR number ] Accuracy from quality scores Find the equation to calculate error probability from quality score on Wikipedia . Comparing fastqc and Nanoplot For comparing fastqc and NanoPlot , check out this blog of the author of NanoPlot, and this thread . Running minimap2 Here\u2019s an example command for minimap2 : minimap2 \\ -a \\ -x [ PARAMETER ] \\ -G [ PARAMETER ] \\ [ REFERENCE ] .fa \\ [ FASTQFILE ] .fastq.gz \\ | samtools sort \\ | samtools view -bh > [ OUTPUT ] .bam Intron sizes Check out the the intron sizes of CACNA1C in e.g. IGV or UCSC genome browser. How does that relate to the parameter -G ? More resources Need e.g. a gtf file? Here\u2019s the ensembl page Project 3: Short-read RNA-seq of mice. Aim: Compare hisat2 (splice-aware) with bowtie2 (splice unaware) while aligning a mouse RNA-seq dataset. In this project you will be working with data from: Singhania A, Graham CM, Gabry\u0161ov\u00e1 L, Moreira-Teixeira L, Stavropoulos E, Pitt JM, et al (2019). Transcriptional profiling unveils type I and II interferon networks in blood and tissues across diseases . Nat Commun. 10:1\u201321. https://doi.org/10.1038/s41467-019-10601-6 Here\u2019s the BioProject page . We\u2019ll be working with a single sample of this project found here . Since the mouse genome is rather large, we have prepared reads for you that originate from chromosome 5. Use those for the project. Download them like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/SRR7822040.chr5_R1.fastq.gz wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/SRR7822040.chr5_R2.fastq.gz Download the mouse reference of chromosome 5 like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/Mus_musculus.GRCm38.dna.primary_assembly.chr5.fa.gz gunzip Mus_musculus.GRCm38.dna.primary_assembly.chr5.fa.gz And download the gtf file for chromosome 5 like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/Mus_musculus.GRCm38.102.chr5.gtf.gz gunzip Mus_musculus.GRCm38.102.chr5.gtf.gz Tasks: Check out the project page, and download one or two samples that interest you (download both the forward and reverse reads from the same sample). Do a QC on the data with fastqc Trim adapters and low quality bases with cutadapt (the adapter sequences are the same as in the exercises). Check which options to use, and align with bowtie2 Check which options to use, and align with hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV. For this, download only a part of the bam file (e.g. the region 5:32592000-32999545 ). Compare different samples in read quality, alignment rates, depth, etc. Run featureCounts on both alignments Compare the count matrices in R or python (Rstudio server is running on the same machine. Approach it with your credentials and username rstudio ) Questions: Check the description at the SRA sample page. What kind of sample is this? How does the quality of the reads look? Anything special about the overrepresented sequences? (Hint: blast some overrepresented sequences, and see what they are) Did trimming improve the QC results? What could be the cause of the warnings/errors in the fastqc reports? What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run featureCounts ). Run your processes on multiple cores! We are now doing computations on a full genome, with full transcriptomic data. This is quite a bit more than we have used during the exercises. Therefore, computations take longer. However, most tools support parallel processing, in which you can specify how many cores you want to use to run in parallel. Your environment contains four cores, so this is also the maximum number of processes you can specify. Below you can find the options used in each command to specify multi-core processing. command option bowtie2-build --threads hisat2-build --threads fastqc --threads cutadapt --cores bowtie2 --threads hisat2 --threads featureCounts -T Example code hisat2 and featureCounts Everything in between <> should be replaced with specific arguments. Here\u2019s an example for hisat2 : hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <foward_reads.fastq.gz> \\ -2 <reverse_reads.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> Example code featureCounts : featureCounts \\ -p \\ -T 2 \\ -a <annotations.gtf> \\ -o <output.counts.txt> \\ <bowtie2_alignment.bam> <hisat2_alignment.bam> Spliced alignments Have a look at IGV on a particular gene, e.g. Pisd Reading in the count data in R You can read in the count data table, and compare the log2 counts of the two aligners like this: cts <- read.delim ( 'project_work/project3/counts/counts.txt' , comment.char = '#' ) plot ( log2 ( cts $ ..alignments.SRR7822040.chr5.bt2.bam ), log2 ( cts $ ..alignments.SRR7822040.chr5.hs2.bam ))","title":"Group work"},{"location":"group_work/#roles-organisation","text":"Project based learning is about learning by doing, but also about peer instruction . This means that you will be both a learner and a teacher. There will be differences in levels among participants, but because of that, some will learn efficiently from people that have just learned, and others will teach and increase their understanding. Each project has tasks and questions . By performing the tasks, you should be able to answer the questions. You should consider the tasks and questions as a guidance. If interesting questions pop up during the project, you are encouraged to work on those. Also, you don\u2019t have to perform all the tasks and answer all the questions. In the afternoon of day 1, you will start on the project. On day 3, you can work on the project in the morning and in the first part of the afternoon. We will conclude the projects with a 10-minute presentation of each group.","title":"Roles &amp; organisation"},{"location":"group_work/#working-directories","text":"Each group has access to a shared working directory. It is mounted in the root directory ( / ). Make a soft link in your home directory: cd ~ ln -s /group_work/<group name> ./ Now you can find your group directory at ~/<group name> . Use this to share files. Warning Do not remove the soft link with rm -r , this will delete the entire source directory. If you want to remove only the softlink, use rm (without -r ), or unlink . More info here .","title":"Working directories"},{"location":"group_work/#project-1-short-read-rna-seq-data-of-arabidopsis-thaliana-grown-in-space","text":"Aim: Compare hisat2 (splice-aware) with bowtie2 (splice unaware) while aligning an Arabidopsis RNA-seq dataset. The analysis of this dataset is reported in this paper: Vandenbrink JP, Herranz R, Poehlman WL, Alex Feltus F, Villacampa A, Ciska M, et al. (2019) RNA-seq analyses of Arabidopsis thaliana seedlings after exposure to blue-light phototropic stimuli in microgravity . Am J Bot. 106:1466\u201376. Reads can be found on the NASA repository here . You can download data with wget . Here is an example for downloading the forward and reverse reads for sample 131: wget -O sample_131_R1.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R1_001.fastq.gz?version = 1 wget -O sample_131_R2.fastq.gz \\ https://genelab-data.ndc.nasa.gov/genelab/static/media/dataset/GLDS-251_rna-seq_13JUN2017HiSeq_Run_Sample_131_UMISS_Hoeksema_ACAGTG_L001_R2_001.fastq.gz?version = 1 Use of -O The name of the file is very long we use the option -O here to give it a shorter name. Download the reference genome sequence like this: wget ftp://ftp.ensemblgenomes.org/pub/plants/release-48/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz gunzip Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz You can download the gtf like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/Araport11_GTF_genes_transposons.Mar202021.noChr.gtf.gz gunzip Araport11_GTF_genes_transposons.Mar202021.noChr.gtf.gz","title":" Project 1: Short-read RNA-seq data of Arabidopsis thaliana grown in space"},{"location":"group_work/#tasks","text":"Check out the project page, and download one or two samples that interest you (download both the forward and reverse reads from the same sample). Do a QC on the data with fastqc Trim adapters and low quality bases with cutadapt (the adapter sequences are the same as in the exercises). Check which options to use, and align with bowtie2 Check which options to use, and align with hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV. For this, download only a part of the bam file (e.g. the region 1:22145-42561 ). Compare different samples in read quality, alignment rates, depth, etc. Run featureCounts on both alignments Compare the count matrices in R or python (Rstudio server is running on the same machine. Approach it with your credentials and username rstudio )","title":"Tasks:"},{"location":"group_work/#questions","text":"What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? (have a look at the CIGAR string) Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run featureCounts ). Run your processes on multiple cores! We are now doing computations on a full genome, with full transcriptomic data. This is quite a bit more than we have used during the exercises. Therefore, computations take longer. However, most tools support parallel processing, in which you can specify how many cores you want to use to run in parallel. Your environment contains four cores, so this is also the maximum number of processes you can specify. Below you can find the options used in each command to specify multi-core processing. command option bowtie2-build --threads hisat2-build --threads fastqc --threads cutadapt --cores bowtie2 --threads hisat2 --threads featureCounts -T Example code hisat2 and featureCounts Everything in between <> should be replaced with specific arguments. Here\u2019s an example for hisat2 : hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <foward_reads.fastq.gz> \\ -2 <reverse_reads.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> Example code featureCounts : featureCounts \\ -p \\ -T 2 \\ -a <annotations.gtf> \\ -o <output.counts.txt> \\ <bowtie2_alignment.bam> <hisat2_alignment.bam> Reading in the count data in R You can read in the count data table, and compare the log2 counts of the two aligners like this: cts <- read.delim ( 'project_work/project3/counts/counts.txt' , comment.char = '#' ) plot ( log2 ( cts $ ..alignments.SRR7822040.chr5.bt2.bam ), log2 ( cts $ ..alignments.SRR7822040.chr5.hs2.bam ))","title":"Questions:"},{"location":"group_work/#project-2-long-read-genome-sequencing","text":"Aim : Align long reads from RNA-seq data to a reference genome. In this project, you will be working with data from: Clark, M. B. et al (2020). Long-read sequencing reveals the complex splicing profile of the psychiatric risk gene CACNA1C in human brain . Molecular Psychiatry, 25(1), 37\u201347. https://doi.org/10.1038/s41380-019-0583-1 . Here you can find the BioProject page . It is Oxford Nanopore Technology sequencing data of amplicons of the gene CACNA1C. It is primarily used to discover new splice variants. In this project, we will align a few of the samples to the reference genome, and assess the quality of reads and the alignment. Download the human reference genome like this: wget ftp://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz","title":" Project 2: Long-read genome sequencing"},{"location":"group_work/#tasks_1","text":"Check out the BioProject, and download two samples that interest you. Perform QC with fastqc Perform QC with NanoPlot Align with minimap2 with default parameters Figure how you should set parameters -x and -G Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare different samples in read quality, alignment rates, depth, etc.","title":"Tasks:"},{"location":"group_work/#questions_1","text":"Have a look at the quality report. What are the average read lengths? Is that expected? What is the average read quality? What kind of accuracy would you expect? Note any differences between fastqc and NanoPlot ? How is that compared to the publication? Check out the options -x and -G of minimap2 . Are the defaults appropriate? You might consider using -x map-ont or -x splice . Do you see differences in the alignment in e.g. IGV? How are spliced alignments stored in the SAM file with the different settings of -x ? How deep is the gene sequenced? Do you already see evidence for splice variants in the alignments? Downloading from SRA prefetch [ SRR number ] fastq-dump --gzip [ SRR number ] Accuracy from quality scores Find the equation to calculate error probability from quality score on Wikipedia . Comparing fastqc and Nanoplot For comparing fastqc and NanoPlot , check out this blog of the author of NanoPlot, and this thread . Running minimap2 Here\u2019s an example command for minimap2 : minimap2 \\ -a \\ -x [ PARAMETER ] \\ -G [ PARAMETER ] \\ [ REFERENCE ] .fa \\ [ FASTQFILE ] .fastq.gz \\ | samtools sort \\ | samtools view -bh > [ OUTPUT ] .bam Intron sizes Check out the the intron sizes of CACNA1C in e.g. IGV or UCSC genome browser. How does that relate to the parameter -G ? More resources Need e.g. a gtf file? Here\u2019s the ensembl page","title":"Questions:"},{"location":"group_work/#project-3-short-read-rna-seq-of-mice","text":"Aim: Compare hisat2 (splice-aware) with bowtie2 (splice unaware) while aligning a mouse RNA-seq dataset. In this project you will be working with data from: Singhania A, Graham CM, Gabry\u0161ov\u00e1 L, Moreira-Teixeira L, Stavropoulos E, Pitt JM, et al (2019). Transcriptional profiling unveils type I and II interferon networks in blood and tissues across diseases . Nat Commun. 10:1\u201321. https://doi.org/10.1038/s41467-019-10601-6 Here\u2019s the BioProject page . We\u2019ll be working with a single sample of this project found here . Since the mouse genome is rather large, we have prepared reads for you that originate from chromosome 5. Use those for the project. Download them like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/SRR7822040.chr5_R1.fastq.gz wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/SRR7822040.chr5_R2.fastq.gz Download the mouse reference of chromosome 5 like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/Mus_musculus.GRCm38.dna.primary_assembly.chr5.fa.gz gunzip Mus_musculus.GRCm38.dna.primary_assembly.chr5.fa.gz And download the gtf file for chromosome 5 like this: wget https://ngs-introduction-training.s3.eu-central-1.amazonaws.com/project3/Mus_musculus.GRCm38.102.chr5.gtf.gz gunzip Mus_musculus.GRCm38.102.chr5.gtf.gz","title":" Project 3: Short-read RNA-seq of mice."},{"location":"group_work/#tasks_2","text":"Check out the project page, and download one or two samples that interest you (download both the forward and reverse reads from the same sample). Do a QC on the data with fastqc Trim adapters and low quality bases with cutadapt (the adapter sequences are the same as in the exercises). Check which options to use, and align with bowtie2 Check which options to use, and align with hisat2 Evaluate the alignment quality (e.g. alignment rates, mapping quality) Compare the bam files of the two aligners in IGV. For this, download only a part of the bam file (e.g. the region 5:32592000-32999545 ). Compare different samples in read quality, alignment rates, depth, etc. Run featureCounts on both alignments Compare the count matrices in R or python (Rstudio server is running on the same machine. Approach it with your credentials and username rstudio )","title":"Tasks:"},{"location":"group_work/#questions_2","text":"Check the description at the SRA sample page. What kind of sample is this? How does the quality of the reads look? Anything special about the overrepresented sequences? (Hint: blast some overrepresented sequences, and see what they are) Did trimming improve the QC results? What could be the cause of the warnings/errors in the fastqc reports? What are the alignment rates? How do the aligners handle splicing? How are spliced alignments stored in the SAM file? Do you see differences in soft clipping? What would be the effect of the aligner if you would be measuring gene expression? (To investigate this you\u2019ll need to run featureCounts ). Run your processes on multiple cores! We are now doing computations on a full genome, with full transcriptomic data. This is quite a bit more than we have used during the exercises. Therefore, computations take longer. However, most tools support parallel processing, in which you can specify how many cores you want to use to run in parallel. Your environment contains four cores, so this is also the maximum number of processes you can specify. Below you can find the options used in each command to specify multi-core processing. command option bowtie2-build --threads hisat2-build --threads fastqc --threads cutadapt --cores bowtie2 --threads hisat2 --threads featureCounts -T Example code hisat2 and featureCounts Everything in between <> should be replaced with specific arguments. Here\u2019s an example for hisat2 : hisat2-build <reference_sequence_fasta> <index_basename> hisat2 \\ -x <index_basename> \\ -1 <foward_reads.fastq.gz> \\ -2 <reverse_reads.fastq.gz> \\ -p <threads> \\ | samtools sort \\ | samtools view -bh \\ > <alignment_file.bam> Example code featureCounts : featureCounts \\ -p \\ -T 2 \\ -a <annotations.gtf> \\ -o <output.counts.txt> \\ <bowtie2_alignment.bam> <hisat2_alignment.bam> Spliced alignments Have a look at IGV on a particular gene, e.g. Pisd Reading in the count data in R You can read in the count data table, and compare the log2 counts of the two aligners like this: cts <- read.delim ( 'project_work/project3/counts/counts.txt' , comment.char = '#' ) plot ( log2 ( cts $ ..alignments.SRR7822040.chr5.bt2.bam ), log2 ( cts $ ..alignments.SRR7822040.chr5.hs2.bam ))","title":"Questions:"},{"location":"precourse/","text":"UNIX As is stated in the course prerequisites at the announcement web page , we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here . If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial . Software We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a jupyter notebook . All participants will be granted access to a personal workspace to be used during the course. The only software you need to install before the course is Integrative Genomics Viewer (IGV) .","title":"Precourse preparations"},{"location":"precourse/#unix","text":"As is stated in the course prerequisites at the announcement web page , we expect participants to have a basic understanding of working with the command line on UNIX-based systems. You can test your UNIX skills with a quiz here . If you don\u2019t have experience with UNIX command line, or if you\u2019re unsure whether you meet the prerequisites, follow our online UNIX tutorial .","title":"UNIX"},{"location":"precourse/#software","text":"We will be mainly working on an Amazon Web Services ( AWS ) Elastic Cloud (EC2) server. Our Ubuntu server behaves like a \u2018normal\u2019 remote server, and can be approached through a jupyter notebook . All participants will be granted access to a personal workspace to be used during the course. The only software you need to install before the course is Integrative Genomics Viewer (IGV) .","title":"Software"},{"location":"day1/intro/","text":"If working independently If you are doing this course independently, you can skip this part. Material Download the presentation","title":"Introduction"},{"location":"day1/intro/#material","text":"Download the presentation","title":"Material"},{"location":"day1/quality_control/","text":"Learning outcomes After having completed this chapter you will be able to: Material Download the presentation fastqc command line documentation cutadapt manual Unix command line E-utilities documentation Exercises Download and evaluate an E. coli dataset Exercise: If you haven\u2019t already done so, create a directory called workdir in your home directory and make the directory your current directory. If working with Docker If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd ~ mkdir workdir cd workdir Check out the dataset at SRA . Exercise: Browse around the SRA entry and answer these questions: A. Is the dataset paired-end or single end? B. Which instrument was used for sequencing? C. What is the read length? D. How many reads do we have? Answers A. paired-end B. Illumina MiSeq C. 2 x 252 bp D. 400596 Make a directory reads in ~/workdir and download the reads from the SRA database using prefetch and fastq-dump from SRA-Tools into the reads directory: Running sra-tools for the first time If you run sra-tools for the first time, you have to set a config file. We\u2019ll be just using a minimal file for now. To do that run: vdb-config --interactive When the GUI pops up, press the key X . The config file will be created in ~/.ncbi/user-settings.mkfg . mkdir reads cd reads prefetch SRR519926 fastq-dump --split-files SRR519926 Exercise: Check whether the download was successful by counting the number of reads in the fastq files and compare it to the SRA entry. Tip A read in a fastq file consists of four lines (more on that at file types ). Use Google to figure out how to count the number of reads in a fastq file. Answer e.g. from this thread on Biostars: ## forward read echo $( cat SRR519926_1.fastq | wc -l ) /4 | bc ## reverse read echo $( cat SRR519926_2.fastq | wc -l ) /4 | bc Run fastqc Exercise: Run fastqc on the fastq files. Tip fastqc accepts multiple files as input, so you can use a wildcard to run fastqc on all the files in one line of code. Use it like this: *.fastq . Answer fastqc *.fastq Exercise: Download the html files to your local computer, and view the results. How is the quality? Where are the problems? Answer There seems to be: Low quality towards the 3\u2019 end (per base sequence quality) Full sequence reads with low quality (per sequence quality scores) Adapters in the sequences (adapter content) We can probably fix most of these issues by trimming. Trim the reads We will use cutadapt for trimming adapters and low quality bases from our reads. The most used adapters for Illumina are TruSeq adapters. To run cutadapt you need to specify the adapter sequences with options -a (or --adapter ) and -A . A reference for the adapter sequences can be found here . Exercise: The script below will trim the sequence reads. However, some parts are missing. We want to: trim the reads based on a base quality of 10 both on the 3\u2019 and 5\u2019 end of the reads, keep only reads with a read length not shorter than 25 base pairs. Fill in the missing options and execute the script to trim the data. Hint Check out the helper of cutadapt with: cutadapt --help ##!/usr/bin/env bash TRIMMED_DIR = trimmed_data READS_DIR = reads mkdir $TRIMMED_DIR cutadapt \\ --adapter AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \\ -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \\ [ QUALITY CUTOFF OPTION ] \\ [ MINIMUM LENGTH OPTION ] \\ --output $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ --paired-output $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq Answer Your script should look like this: ##!/usr/bin/env bash TRIMMED_DIR = trimmed_data READS_DIR = reads mkdir $TRIMMED_DIR cutadapt \\ --adapter AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \\ -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \\ --quality-cutoff 10 ,10 \\ --minimum-length 25 \\ --output $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ --paired-output $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq The use of \\ In the script above you see that we\u2019re using \\ at the end of many lines. We use it to tell bash to ignore the newlines. If we would not do it, the cutadapt command would become a very long line, and the script would become very difficult to read. It is in general good practice to put every option of a long command on a newline in your script and use \\ to ignore the newlines when executing. Exercise: Run fastqc on the trimmed fastq files and answer these questions: A. Has the quality improved? B. How many reads do we have left? Answers Running fastqc : cd ~/workdir/trimmed_data fastqc paired_trimmed*.fastq A. Yes, low quality 3\u2019 end, per sequence quality and adapter sequences have improved. B. 315904","title":"Quality control"},{"location":"day1/quality_control/#learning-outcomes","text":"After having completed this chapter you will be able to:","title":"Learning outcomes"},{"location":"day1/quality_control/#material","text":"Download the presentation fastqc command line documentation cutadapt manual Unix command line E-utilities documentation","title":"Material"},{"location":"day1/quality_control/#exercises","text":"","title":"Exercises"},{"location":"day1/quality_control/#download-and-evaluate-an-e-coli-dataset","text":"Exercise: If you haven\u2019t already done so, create a directory called workdir in your home directory and make the directory your current directory. If working with Docker If you have mounted your local directory to /root/workdir , this directory should already exist. Answer cd ~ mkdir workdir cd workdir Check out the dataset at SRA . Exercise: Browse around the SRA entry and answer these questions: A. Is the dataset paired-end or single end? B. Which instrument was used for sequencing? C. What is the read length? D. How many reads do we have? Answers A. paired-end B. Illumina MiSeq C. 2 x 252 bp D. 400596 Make a directory reads in ~/workdir and download the reads from the SRA database using prefetch and fastq-dump from SRA-Tools into the reads directory: Running sra-tools for the first time If you run sra-tools for the first time, you have to set a config file. We\u2019ll be just using a minimal file for now. To do that run: vdb-config --interactive When the GUI pops up, press the key X . The config file will be created in ~/.ncbi/user-settings.mkfg . mkdir reads cd reads prefetch SRR519926 fastq-dump --split-files SRR519926 Exercise: Check whether the download was successful by counting the number of reads in the fastq files and compare it to the SRA entry. Tip A read in a fastq file consists of four lines (more on that at file types ). Use Google to figure out how to count the number of reads in a fastq file. Answer e.g. from this thread on Biostars: ## forward read echo $( cat SRR519926_1.fastq | wc -l ) /4 | bc ## reverse read echo $( cat SRR519926_2.fastq | wc -l ) /4 | bc","title":"Download and evaluate an E. coli dataset"},{"location":"day1/quality_control/#run-fastqc","text":"Exercise: Run fastqc on the fastq files. Tip fastqc accepts multiple files as input, so you can use a wildcard to run fastqc on all the files in one line of code. Use it like this: *.fastq . Answer fastqc *.fastq Exercise: Download the html files to your local computer, and view the results. How is the quality? Where are the problems? Answer There seems to be: Low quality towards the 3\u2019 end (per base sequence quality) Full sequence reads with low quality (per sequence quality scores) Adapters in the sequences (adapter content) We can probably fix most of these issues by trimming.","title":"Run fastqc"},{"location":"day1/quality_control/#trim-the-reads","text":"We will use cutadapt for trimming adapters and low quality bases from our reads. The most used adapters for Illumina are TruSeq adapters. To run cutadapt you need to specify the adapter sequences with options -a (or --adapter ) and -A . A reference for the adapter sequences can be found here . Exercise: The script below will trim the sequence reads. However, some parts are missing. We want to: trim the reads based on a base quality of 10 both on the 3\u2019 and 5\u2019 end of the reads, keep only reads with a read length not shorter than 25 base pairs. Fill in the missing options and execute the script to trim the data. Hint Check out the helper of cutadapt with: cutadapt --help ##!/usr/bin/env bash TRIMMED_DIR = trimmed_data READS_DIR = reads mkdir $TRIMMED_DIR cutadapt \\ --adapter AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \\ -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \\ [ QUALITY CUTOFF OPTION ] \\ [ MINIMUM LENGTH OPTION ] \\ --output $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ --paired-output $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq Answer Your script should look like this: ##!/usr/bin/env bash TRIMMED_DIR = trimmed_data READS_DIR = reads mkdir $TRIMMED_DIR cutadapt \\ --adapter AGATCGGAAGAGCACACGTCTGAACTCCAGTCA \\ -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT \\ --quality-cutoff 10 ,10 \\ --minimum-length 25 \\ --output $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ --paired-output $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ $READS_DIR /SRR519926_1.fastq \\ $READS_DIR /SRR519926_2.fastq The use of \\ In the script above you see that we\u2019re using \\ at the end of many lines. We use it to tell bash to ignore the newlines. If we would not do it, the cutadapt command would become a very long line, and the script would become very difficult to read. It is in general good practice to put every option of a long command on a newline in your script and use \\ to ignore the newlines when executing. Exercise: Run fastqc on the trimmed fastq files and answer these questions: A. Has the quality improved? B. How many reads do we have left? Answers Running fastqc : cd ~/workdir/trimmed_data fastqc paired_trimmed*.fastq A. Yes, low quality 3\u2019 end, per sequence quality and adapter sequences have improved. B. 315904","title":"Trim the reads"},{"location":"day1/sequencing_technologies/","text":"Learning outcomes After having completed this chapter you will be able to: Describe the major applications of next generation sequencing Reproduce the most frequently used sequencing methods Describe the major steps taken during library preparation for Illumina sequencing Explain why the length of the sequencing reads of Illumina sequencing are limited Describe the general methods used for Oxford Nanopore Sequencing and PacBio sequencing Material Download the presentation Illumina sequencing by synthesis on YouTube NEBnext library preparation poster","title":"Sequencing technologies"},{"location":"day1/sequencing_technologies/#learning-outcomes","text":"After having completed this chapter you will be able to: Describe the major applications of next generation sequencing Reproduce the most frequently used sequencing methods Describe the major steps taken during library preparation for Illumina sequencing Explain why the length of the sequencing reads of Illumina sequencing are limited Describe the general methods used for Oxford Nanopore Sequencing and PacBio sequencing","title":"Learning outcomes"},{"location":"day1/sequencing_technologies/#material","text":"Download the presentation Illumina sequencing by synthesis on YouTube NEBnext library preparation poster","title":"Material"},{"location":"day1/server_login/","text":"Learning outcomes Note You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line. After having completed this chapter you will be able to: Use the command line to: Make a directory Change file permissions to \u2018executable\u2019 Run a bash script Pipe data from and to a file or other executable Program a loop in bash Choose your platform In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker. If you are doing the course with a teacher , you will have to login to the remote server. Therefore choose: Cloud notebook If you are doing this course independently (i.e. without a teacher) choose either: conda Docker Cloud notebook If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002 ) in your browser. This should result in the following page: Type your password, and proceed to the notebook home page. This page contains all the files in your working directory (if there are any). Most of the exercises will be executed through the command line. Here\u2019s a video that explains how to use JupyterLab to use a terminal and work with scripts: If you rather read, here\u2019s written explanation how to work with JupyterLab. First, let\u2019s open the terminal. Find it at New > Terminal : For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. You can generate and edit scripts with New > Text File : Once you have opened a script you can change the code highlighting. This is convenient for writing the code. The text editor will automatically change the highlighting based on the file extension (e.g. .py extension will result in python syntax highlighting). You can change or set the syntax highlighting by clicking the button on the bottom of the page. We will be using mainly shell scripting in this course, so here\u2019s an example for adjusting it to shell syntax highlighting: Docker Material Instructions to install docker Instructions to set up to container Exercises First login Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal): Modify the script Modify the path after -v to the working directory on your computer before running it. docker run \\ --rm \\ -e JUPYTER_ENABLE_LAB = yes \\ -v /path/to/local/workdir:/home/jovyan \\ -p 8888 :8888 \\ geertvangeest/ngs-introduction-jupyter:2021.5 \\ start-notebook.sh If this command has run successfully, you will find a link and token in the console, e.g.: http://127.0.0.1:8888/?token = 4be8d916e89afad166923de5ce5th1s1san3xamp13 Copy this URL into your browser, and you will be able to use the jupyter notebook. The option -v mounts a local directory in your computer to the directory /home/jovyan in the docker container (\u2018jovyan\u2019 is the default user for jupyter containers). In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The part geertvangeest/ngs-introduction-jupyter:2021.5 is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. conda If you have a conda installation on your local computer, you can install the required software using conda. You can build the environment from ngs-introduction.yml Generate the conda environment like this: conda env create --name ngs-introduction -f ngs-introduction.yml The yaml file probably only works for Linux systems If you want to use the conda environment on a different OS, use: conda create -n ngs-introduction python = 3 .8 conda activate ngs-introduction conda install -y -c bioconda \\ samtools \\ bwa \\ fastqc \\ sra-tools \\ cutadapt \\ bowtie2 \\ hisat2 \\ subread \\ entrez-direct \\ minimap2 This will create the conda environment ngs-introduction Activate it like so: conda activate ngs-introduction After successful installation and activating the environment all the software required to do the exercises should be available. If you are doing project 2 (long reads) If you are doing the project 2 as part of the course, you will need to install NanoPlot as well, using pip : pip install NanoPlot A UNIX command line interface (CLI) refresher Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory. Make a new directory Login to the server and use the command line to make a directory called workdir . Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts File permissions Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer You can use your remote script editor to edit your script. Otherwise you can use nano to edit it: nano new_script.sh The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here . Redirection: > and | In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory. Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l Variables Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE shell scripts Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l","title":"Setup + UNIX refresher"},{"location":"day1/server_login/#learning-outcomes","text":"Note You might already be able to do some or all of these learning outcomes. If so, you can go through the corresponding exercises quickly. The general aim of this chapter is to work comfortably on a remote server by using the command line. After having completed this chapter you will be able to: Use the command line to: Make a directory Change file permissions to \u2018executable\u2019 Run a bash script Pipe data from and to a file or other executable Program a loop in bash Choose your platform In this part we will show you how to access the cloud server, or setup your computer to do the exercises with conda or with Docker. If you are doing the course with a teacher , you will have to login to the remote server. Therefore choose: Cloud notebook If you are doing this course independently (i.e. without a teacher) choose either: conda Docker Cloud notebook If you are participating in this course with a teacher, you have received a link and a password. Copy-paste the link (including the port, e.g.: http://12.345.678.91:10002 ) in your browser. This should result in the following page: Type your password, and proceed to the notebook home page. This page contains all the files in your working directory (if there are any). Most of the exercises will be executed through the command line. Here\u2019s a video that explains how to use JupyterLab to use a terminal and work with scripts: If you rather read, here\u2019s written explanation how to work with JupyterLab. First, let\u2019s open the terminal. Find it at New > Terminal : For a.o. efficiency and reproducibility it makes sense to execute your commands from a script. You can generate and edit scripts with New > Text File : Once you have opened a script you can change the code highlighting. This is convenient for writing the code. The text editor will automatically change the highlighting based on the file extension (e.g. .py extension will result in python syntax highlighting). You can change or set the syntax highlighting by clicking the button on the bottom of the page. We will be using mainly shell scripting in this course, so here\u2019s an example for adjusting it to shell syntax highlighting: Docker","title":"Learning outcomes"},{"location":"day1/server_login/#material","text":"Instructions to install docker Instructions to set up to container","title":"Material"},{"location":"day1/server_login/#exercises","text":"","title":"Exercises"},{"location":"day1/server_login/#first-login","text":"Docker can be used to run an entire isolated environment in a container. This means that we can run the software with all its dependencies required for this course locally in your computer. Independent of your operating system. In the video below there\u2019s a tutorial on how to set up a docker container for this course. Note that you will need administrator rights, and that if you are using Windows, you need the latest version of Windows 10. The command to run the environment required for this course looks like this (in a terminal): Modify the script Modify the path after -v to the working directory on your computer before running it. docker run \\ --rm \\ -e JUPYTER_ENABLE_LAB = yes \\ -v /path/to/local/workdir:/home/jovyan \\ -p 8888 :8888 \\ geertvangeest/ngs-introduction-jupyter:2021.5 \\ start-notebook.sh If this command has run successfully, you will find a link and token in the console, e.g.: http://127.0.0.1:8888/?token = 4be8d916e89afad166923de5ce5th1s1san3xamp13 Copy this URL into your browser, and you will be able to use the jupyter notebook. The option -v mounts a local directory in your computer to the directory /home/jovyan in the docker container (\u2018jovyan\u2019 is the default user for jupyter containers). In that way, you have files available both in the container and on your computer. Use this directory on your computer to e.g. visualise data with IGV. Change the first path to a path on your computer that you want to use as a working directory. Don\u2019t mount directly in the home dir Don\u2019t directly mount your local directory to the home directory ( /root ). This will lead to unexpected behaviour. The part geertvangeest/ngs-introduction-jupyter:2021.5 is the image we are going to load into the container. The image contains all the information about software and dependencies needed for this course. When you run this command for the first time it will download the image. Once it\u2019s on your computer, it will start immediately. conda If you have a conda installation on your local computer, you can install the required software using conda. You can build the environment from ngs-introduction.yml Generate the conda environment like this: conda env create --name ngs-introduction -f ngs-introduction.yml The yaml file probably only works for Linux systems If you want to use the conda environment on a different OS, use: conda create -n ngs-introduction python = 3 .8 conda activate ngs-introduction conda install -y -c bioconda \\ samtools \\ bwa \\ fastqc \\ sra-tools \\ cutadapt \\ bowtie2 \\ hisat2 \\ subread \\ entrez-direct \\ minimap2 This will create the conda environment ngs-introduction Activate it like so: conda activate ngs-introduction After successful installation and activating the environment all the software required to do the exercises should be available. If you are doing project 2 (long reads) If you are doing the project 2 as part of the course, you will need to install NanoPlot as well, using pip : pip install NanoPlot","title":"First login"},{"location":"day1/server_login/#a-unix-command-line-interface-cli-refresher","text":"Most bioinformatics software are UNIX based and are executed through the CLI. When working with NGS data, it is therefore convenient to improve your knowledge on UNIX. For this course, we need basic understanding of UNIX CLI, so here are some exercises to refresh your memory.","title":"A UNIX command line interface (CLI) refresher"},{"location":"day1/server_login/#make-a-new-directory","text":"Login to the server and use the command line to make a directory called workdir . Answer cd mkdir workdir Make a directory scripts within ~/workdir and make it your current directory. Answer cd workdir mkdir scripts cd scripts","title":"Make a new directory"},{"location":"day1/server_login/#file-permissions","text":"Generate an empty script in your newly made directory ~/workdir/scripts like this: touch new_script.sh Add a command to this script that writes \u201cSIB courses are great!\u201d (or something you can better relate to.. ) to stdout, and try to run it. Answer You can use your remote script editor to edit your script. Otherwise you can use nano to edit it: nano new_script.sh The script should look like this: #!/usr/bin/env bash echo \"SIB courses are great!\" Usually, you can run it like this: ./new_script.sh But there\u2019s an error: bash: ./new_script.sh: Permission denied Why is there an error? Hint Use ls -lh new_script.sh to check the permissions. Answer ls -lh new_script.sh gives: -rw-r--r-- 1 user group 51B Nov 11 16 :21 new_script.sh There\u2019s no x in the permissions string. You should change at least the permissions of the user. Make the script executable for yourself, and run it. Answer Change permissions: chmod u+x new_script.sh ls -lh new_script.sh now gives: -rwxr--r-- 1 user group 51B Nov 11 16:21 new_script.sh So it should be executable: ./new_script.sh More on chmod and file permissions here .","title":"File permissions"},{"location":"day1/server_login/#redirection-and","text":"In the root directory (go there like this: cd / ) there are a range of system directories and files. Write the names of all directories and files to a file called system_dirs.txt in your home directory. Answer ls / > ~/system_dirs.txt The command wc -l counts the number of lines, and can read from stdin. Make a one-liner with a pipe | symbol to find out how many system directories and files there are. Answer ls / | wc -l","title":"Redirection: &gt; and |"},{"location":"day1/server_login/#variables","text":"Store system_dirs.txt as variable (like this: VAR=variable ), and use wc -l on that variable to count the number of lines in the file. Answer FILE = system_dirs.txt wc -l $FILE","title":"Variables"},{"location":"day1/server_login/#shell-scripts","text":"Make a shell script that automatically counts the number of system directories and files. Answer Make a script called e.g. current_system_dirs.sh : #!/usr/bin/env bash cd / ls | wc -l","title":"shell scripts"},{"location":"day2/file_types/","text":"Material Download the presentation File definition websites: FASTQ (wikipedia) GFF (ensembl) VCF (Wikipedia) SAM: Wikipedia samtools Zhuyi Xue","title":"File types"},{"location":"day2/file_types/#material","text":"Download the presentation File definition websites: FASTQ (wikipedia) GFF (ensembl) VCF (Wikipedia) SAM: Wikipedia samtools Zhuyi Xue","title":"Material"},{"location":"day2/read_alignment/","text":"Material Download the presentation Unix command line E-utilities documentation bowtie2 manual Exercises Prepare the reference sequence Retrieve the reference sequence using esearch and efetch : REFERENCE_DIR = ~/workdir/ref_genome/ mkdir $REFERENCE_DIR cd $REFERENCE_DIR esearch -db nuccore -query 'U00096' \\ | efetch -format fasta > ecoli-strK12-MG1655.fasta Exercise: Check out the documentation of bowtie2-build , and build a index for bowtie2 using default options. Answer bowtie2-build ecoli-strK12-MG1655.fasta ecoli-strK12-MG1655.fasta Align the reads with bowtie2 Exercise: Check out the bowtie2 manual here . We are going to align the sequences in paired-end mode. What are the options we\u2019ll minimally need? Answer According to the usage of bowtie2 : bowtie2 [ options ] * -x <bt2-idx> { -1 <m1> -2 <m2> | -U <r> | --interleaved <i> | --sra-acc <acc> | b <bam> } We\u2019ll need the options: -x to point to our index -1 and -2 to point to our forward and reverse reads Exercise: Try to understand what the script below does, and run it. ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data REFERENCE_DIR = ~/workdir/ref_genome/ ALIGNED_DIR = ~/workdir/alignment_output mkdir $ALIGNED_DIR bowtie2 \\ -x $REFERENCE_DIR /ecoli-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ > $ALIGNED_DIR /SRR519926.sam We\u2019ll go deeper into alignment statistics tomorrow, but bowtie2 writes already some statistics to stdout. General alignment rates seem okay, but there are quite some non-concordant alignments. That doesn\u2019t sound good. Check out the explanation about concordance at the bowtie2 manual . Can you guess what the reason could be?","title":"Read alignment"},{"location":"day2/read_alignment/#material","text":"Download the presentation Unix command line E-utilities documentation bowtie2 manual","title":"Material"},{"location":"day2/read_alignment/#exercises","text":"","title":"Exercises"},{"location":"day2/read_alignment/#prepare-the-reference-sequence","text":"Retrieve the reference sequence using esearch and efetch : REFERENCE_DIR = ~/workdir/ref_genome/ mkdir $REFERENCE_DIR cd $REFERENCE_DIR esearch -db nuccore -query 'U00096' \\ | efetch -format fasta > ecoli-strK12-MG1655.fasta Exercise: Check out the documentation of bowtie2-build , and build a index for bowtie2 using default options. Answer bowtie2-build ecoli-strK12-MG1655.fasta ecoli-strK12-MG1655.fasta Align the reads with bowtie2 Exercise: Check out the bowtie2 manual here . We are going to align the sequences in paired-end mode. What are the options we\u2019ll minimally need? Answer According to the usage of bowtie2 : bowtie2 [ options ] * -x <bt2-idx> { -1 <m1> -2 <m2> | -U <r> | --interleaved <i> | --sra-acc <acc> | b <bam> } We\u2019ll need the options: -x to point to our index -1 and -2 to point to our forward and reverse reads Exercise: Try to understand what the script below does, and run it. ##!/usr/bin/env bash TRIMMED_DIR = ~/workdir/trimmed_data REFERENCE_DIR = ~/workdir/ref_genome/ ALIGNED_DIR = ~/workdir/alignment_output mkdir $ALIGNED_DIR bowtie2 \\ -x $REFERENCE_DIR /ecoli-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR /paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR /paired_trimmed_SRR519926_2.fastq \\ > $ALIGNED_DIR /SRR519926.sam We\u2019ll go deeper into alignment statistics tomorrow, but bowtie2 writes already some statistics to stdout. General alignment rates seem okay, but there are quite some non-concordant alignments. That doesn\u2019t sound good. Check out the explanation about concordance at the bowtie2 manual . Can you guess what the reason could be?","title":"Prepare the reference sequence"},{"location":"day2/samtools/","text":"Material samtools documentation Exercises Alignment statistics Exercise: Check out the statistics of the E. coli alignment by using samtools flagstat . Find the documentation here . Anything that draws your attention? Answer Code: cd ~/workdir/alignment_output/ samtools flagstat SRR519926.sam resulting in: 631808 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 627753 + 0 mapped (99.36% : N/A) 631808 + 0 paired in sequencing 315904 + 0 read1 315904 + 0 read2 302430 + 0 properly paired (47.87% : N/A) 624508 + 0 with itself and mate mapped 3245 + 0 singletons (0.51% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Of the reads, 38.44% is properly paired. The rest isn\u2019t. Proper pairing is quite hard to interpret. It usually means that the 0x2 flag (each segment properly aligned according to the aligner) is false. In this case it means that the insert size is high for a lot of sequences. That is because the insert size distribution is very wide. You can find info on insert size distribution like this: samtools stats SRR519926.sam | grep ^SN | cut -f 2,3 Now look at insert size average and insert size standard deviation . You can see the standard deviation is higher than the average, suggesting a wide distribution. Compression, sorting and indexing The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: Samtools writes to stdout By default, samtools writes it\u2019s output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh SRR519926.sam > SRR519926.bam By using ls -lh , you can find out that SRR519926.sam has a size of 223 Mb, while SRR519926.bam is only 67 Mb. To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools sort SRR519926.bam > SRR519926.sorted.bam samtools index SRR519926.sorted.bam Filtering With samtools view you can easily filter your alignment file based on flags. One thing that might be sensible to do at some point is to filter out unmapped reads. Exercise: Check out the flag that you would need to filter for mapped reads. It\u2019s at page 7 of the SAM documentation . Answer You will need the 0x4 flag. Filtering against unmapped reads (leaving only mapped reads) with samtools view would look like this: samtools view -bh -F 0x4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam or: samtools view -bh -F 4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam Exercise: Write a command that outputs only the unmapped reads (so the opposite of the example). How many reads are in there? Is that the same as what we expect based on the output of samtools flagstat ? Tip Check out the -f and -c options of samtools view Answer Filter like this: samtools view -bh -f 0x4 SRR519926.sorted.bam > SRR519926.sorted.unmapped.bam Counting like this: samtools view -c SRR519926.sorted.unmapped.bam This should correspond to the output of samtools flagstat (631808 - 627753 = 4055) samtools view also enables you to filter alignments in a specific region. This can be convenient if you don\u2019t want to work with huge alignment files and if you\u2019re only interested in alignments in a particular region. Region filtering only works for sorted and indexed alignment files. Exercise: Filter our sorted and indexed BAM file for the region between 2000 and 2500 kb, and output it as a BAM file with a header. Tip: Specifying a region Our E. coli genome has only one chromosome, because only one line starts with > in the fasta file cd ~/workdir/ref_genome grep \">\" ecoli-strK12-MG1655.fasta gives: >U00096.3 Escherichia coli str. K-12 substr. MG1655, complete genome The part after the first space in the title is cut off for the alignment reference. So the code for specifying a region would be: U00096.3:START-END Answer cd ~/workdir/alignment_output samtools view -bh SRR519926.sorted.bam U00096.3:2000000-2500000 > SRR519926.sorted.region.bam Redirection Samtools is easy to use in a pipe. In this case you can replace the input file with a - . For example, you can sort and compress the output of your alignment software in a pipe like this: my_alignment_command \\ | samtools sort - \\ | samtools view -bh - \\ > alignment.bam The use of - In the modern versions of samtools, the use of - is not needed for most cases, so without an input file it reads from stdin. However, if you\u2019re not sure, it\u2019s better to be safe than sorry. Exercise: Write a script that maps the reads with bowtie2 (see chapter 2 of read alignment ), sorts them, takes only the mapped reads, and outputs them as a BAM file with a header. Answer ##!/usr/bin/env bash TRIMMED_DIR=~/workdir/trimmed_data REFERENCE_DIR=~/workdir/ref_genome ALIGNED_DIR=~/workdir/alignment_output bowtie2 \\ -x $REFERENCE_DIR/ecoli-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR/paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR/paired_trimmed_SRR519926_2.fastq \\ | samtools sort - \\ | samtools view -F 0x4 -bh - \\ > $ALIGNED_DIR/SRR519926.sorted.mapped.frompipe.bam","title":"Samtools"},{"location":"day2/samtools/#material","text":"samtools documentation","title":"Material"},{"location":"day2/samtools/#exercises","text":"","title":"Exercises"},{"location":"day2/samtools/#alignment-statistics","text":"Exercise: Check out the statistics of the E. coli alignment by using samtools flagstat . Find the documentation here . Anything that draws your attention? Answer Code: cd ~/workdir/alignment_output/ samtools flagstat SRR519926.sam resulting in: 631808 + 0 in total (QC-passed reads + QC-failed reads) 0 + 0 secondary 0 + 0 supplementary 0 + 0 duplicates 627753 + 0 mapped (99.36% : N/A) 631808 + 0 paired in sequencing 315904 + 0 read1 315904 + 0 read2 302430 + 0 properly paired (47.87% : N/A) 624508 + 0 with itself and mate mapped 3245 + 0 singletons (0.51% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ>=5) Of the reads, 38.44% is properly paired. The rest isn\u2019t. Proper pairing is quite hard to interpret. It usually means that the 0x2 flag (each segment properly aligned according to the aligner) is false. In this case it means that the insert size is high for a lot of sequences. That is because the insert size distribution is very wide. You can find info on insert size distribution like this: samtools stats SRR519926.sam | grep ^SN | cut -f 2,3 Now look at insert size average and insert size standard deviation . You can see the standard deviation is higher than the average, suggesting a wide distribution.","title":"Alignment statistics"},{"location":"day2/samtools/#compression-sorting-and-indexing","text":"The command samtools view is very versatile. It takes an alignment file and writes a filtered or processed alignment to the output. You can for example use it to compress your SAM file into a BAM file. Let\u2019s start with that. Exercise : compress our SAM file into a BAM file and include the header in the output. For this, use the -b and -h options. Find the required documentation here . How much was the disk space reduced by compressing the file? Tip: Samtools writes to stdout By default, samtools writes it\u2019s output to stdout. This means that you need to redirect your output to a file with > or use the the output option -o . Answer samtools view -bh SRR519926.sam > SRR519926.bam By using ls -lh , you can find out that SRR519926.sam has a size of 223 Mb, while SRR519926.bam is only 67 Mb. To look up specific alignments, it is convenient to have your alignment file indexed. An indexing can be compared to a kind of \u2018phonebook\u2019 of your sequence alignment file. Indexing can be done with samtools as well, but it first needs to be sorted on coordinate (i.e. the alignment location). You can do it like this: samtools sort SRR519926.bam > SRR519926.sorted.bam samtools index SRR519926.sorted.bam","title":"Compression, sorting and indexing"},{"location":"day2/samtools/#filtering","text":"With samtools view you can easily filter your alignment file based on flags. One thing that might be sensible to do at some point is to filter out unmapped reads. Exercise: Check out the flag that you would need to filter for mapped reads. It\u2019s at page 7 of the SAM documentation . Answer You will need the 0x4 flag. Filtering against unmapped reads (leaving only mapped reads) with samtools view would look like this: samtools view -bh -F 0x4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam or: samtools view -bh -F 4 SRR519926.sorted.bam > SRR519926.sorted.mapped.bam Exercise: Write a command that outputs only the unmapped reads (so the opposite of the example). How many reads are in there? Is that the same as what we expect based on the output of samtools flagstat ? Tip Check out the -f and -c options of samtools view Answer Filter like this: samtools view -bh -f 0x4 SRR519926.sorted.bam > SRR519926.sorted.unmapped.bam Counting like this: samtools view -c SRR519926.sorted.unmapped.bam This should correspond to the output of samtools flagstat (631808 - 627753 = 4055) samtools view also enables you to filter alignments in a specific region. This can be convenient if you don\u2019t want to work with huge alignment files and if you\u2019re only interested in alignments in a particular region. Region filtering only works for sorted and indexed alignment files. Exercise: Filter our sorted and indexed BAM file for the region between 2000 and 2500 kb, and output it as a BAM file with a header. Tip: Specifying a region Our E. coli genome has only one chromosome, because only one line starts with > in the fasta file cd ~/workdir/ref_genome grep \">\" ecoli-strK12-MG1655.fasta gives: >U00096.3 Escherichia coli str. K-12 substr. MG1655, complete genome The part after the first space in the title is cut off for the alignment reference. So the code for specifying a region would be: U00096.3:START-END Answer cd ~/workdir/alignment_output samtools view -bh SRR519926.sorted.bam U00096.3:2000000-2500000 > SRR519926.sorted.region.bam","title":"Filtering"},{"location":"day2/samtools/#redirection","text":"Samtools is easy to use in a pipe. In this case you can replace the input file with a - . For example, you can sort and compress the output of your alignment software in a pipe like this: my_alignment_command \\ | samtools sort - \\ | samtools view -bh - \\ > alignment.bam The use of - In the modern versions of samtools, the use of - is not needed for most cases, so without an input file it reads from stdin. However, if you\u2019re not sure, it\u2019s better to be safe than sorry. Exercise: Write a script that maps the reads with bowtie2 (see chapter 2 of read alignment ), sorts them, takes only the mapped reads, and outputs them as a BAM file with a header. Answer ##!/usr/bin/env bash TRIMMED_DIR=~/workdir/trimmed_data REFERENCE_DIR=~/workdir/ref_genome ALIGNED_DIR=~/workdir/alignment_output bowtie2 \\ -x $REFERENCE_DIR/ecoli-strK12-MG1655.fasta \\ -1 $TRIMMED_DIR/paired_trimmed_SRR519926_1.fastq \\ -2 $TRIMMED_DIR/paired_trimmed_SRR519926_2.fastq \\ | samtools sort - \\ | samtools view -F 0x4 -bh - \\ > $ALIGNED_DIR/SRR519926.sorted.mapped.frompipe.bam","title":"Redirection"},{"location":"day3/igv_visualisation/","text":"Material The exercises below are partly based on this tutorial from the Griffith lab . Exercises A first glance: the E. coli dataset Index the alignment that was filtered for the region between 2000 and 2500 kb: cd ~/workdir/alignment_output samtools index SRR519926.sorted.region.bam Download it together with it\u2019s index file ( SRR519926.sorted.region.bam.bai ) and the reference genome ( ecoli-strK12-MG1655.fasta ) to your desktop. If working with Docker If you are working with Docker, you can find the files in the working directory that you mounted to the docker container (with the -v option). So if you have used -v C:\\Users\\myusername\\ngs-course:/root/workdir , your files will be in C:\\Users\\myusername\\ngs-course . Load the genome ( .fasta ) into IGV: Genomes > Load Genome from File\u2026 Load the alignment file ( .bam ): File > Load from File\u2026 Zoom in into the region U00096.3:2046000-2048000. You can do this in two ways: With the search box Select the region in the location bar View the reads as pairs, by right click on the reads and select View as pairs Exercise: There are lot of reads that are coloured red. Why is that? Answer According to IGV , reads are coloured red if the insert size is larger than expected. As you remember, this dataset has a very large variation in insert size. Modify the popup text behaviour by clicking on the yellow balloon to Show Details on Click : Exercise: Click on one of the reads. What kind of information is there? Answer Most of the information from the SAM file. Colour the alignment by pair orientation by right clicking on the reads, and click Color alignments by > read strand . HCC1143 data set For this part, we will be using publicly available Illumina sequence data generated for the HCC1143 cell line. The HCC1143 cell line was generated from a 52 year old caucasian woman with breast cancer. Sequence reads were aligned to version GRCh37 of the human reference genome. We will be working with subsets of aligned reads in the region: chromosome 21: 19,000,000 - 20,000,000. The BAM files containing these reads for the cancer cell line and the matched normal are: HCC1143.normal.21.19M-20M.bam HCC1143.normal.21.19M-20M.bam.bai A lot of model-organism genomes are built-in IGV. Select the human genome version hg19 from the drop down menu: Select File > Load from File\u2026 from the main menu and select the BAM file HCC1143.normal.21.19M-20M.bam using the file browser. This BAM file only contains data for a 1 Megabase region of chromosome 21. Let\u2019s navigate there to see what genes this region covers. To do so, navigate to chr21:19,000,000-20,000,000 . Navigate to the gene CHODL by typing it in the search box. Load the dbsnp annotations by clicking File > Load From Server\u2026 > Annotations > Variation and Repeats > dbSNP 1.4.7 Like you did with the gene (i.e. by typing it in the search box), navigate to SNP rs3827160 that is annotated in the loaded file. Click on the coverage track where the SNP is: Exercise: What is the sequence coverage for that base? And the percentage T? Answer The coverage is 62, and 25 reads (40%) T. Navigate to region chr21:19,800,320-19,818,162 Load repeat tracks by selecting File > Load from Server\u2026 from the main menu and then select Annotations > Variation and Repeats > Repeat Masker Note This might take a while to load. Right click in the alignment track and select Color alignments by > insert size and pair orientation Exercise: Why are some reads coloured white? What can be the cause of that? Answer The white coloured reads have a map quality of 0 (click on the read to find the mapping quality). The cause of that is a LINE repeat region called L1PA3. Navigate to region chr21:19,324,500-19,331,500 Right click in the main alignment track and select: Expanded View as pairs Color alignments by > insert size and pair orientation Sort alignments by > insert size Exercise: What is the insert size of the red flagged read pairs? Can you estimate the size of the deletion? Answer The insert size is about 2.8 kb. This includes the reads. The deletion should be about 2.5 - 2.6 kb.","title":"IGV and visualisation"},{"location":"day3/igv_visualisation/#material","text":"The exercises below are partly based on this tutorial from the Griffith lab .","title":"Material"},{"location":"day3/igv_visualisation/#exercises","text":"","title":"Exercises"},{"location":"day3/igv_visualisation/#a-first-glance-the-e-coli-dataset","text":"Index the alignment that was filtered for the region between 2000 and 2500 kb: cd ~/workdir/alignment_output samtools index SRR519926.sorted.region.bam Download it together with it\u2019s index file ( SRR519926.sorted.region.bam.bai ) and the reference genome ( ecoli-strK12-MG1655.fasta ) to your desktop. If working with Docker If you are working with Docker, you can find the files in the working directory that you mounted to the docker container (with the -v option). So if you have used -v C:\\Users\\myusername\\ngs-course:/root/workdir , your files will be in C:\\Users\\myusername\\ngs-course . Load the genome ( .fasta ) into IGV: Genomes > Load Genome from File\u2026 Load the alignment file ( .bam ): File > Load from File\u2026 Zoom in into the region U00096.3:2046000-2048000. You can do this in two ways: With the search box Select the region in the location bar View the reads as pairs, by right click on the reads and select View as pairs Exercise: There are lot of reads that are coloured red. Why is that? Answer According to IGV , reads are coloured red if the insert size is larger than expected. As you remember, this dataset has a very large variation in insert size. Modify the popup text behaviour by clicking on the yellow balloon to Show Details on Click : Exercise: Click on one of the reads. What kind of information is there? Answer Most of the information from the SAM file. Colour the alignment by pair orientation by right clicking on the reads, and click Color alignments by > read strand .","title":"A first glance: the E. coli dataset"},{"location":"day3/igv_visualisation/#hcc1143-data-set","text":"For this part, we will be using publicly available Illumina sequence data generated for the HCC1143 cell line. The HCC1143 cell line was generated from a 52 year old caucasian woman with breast cancer. Sequence reads were aligned to version GRCh37 of the human reference genome. We will be working with subsets of aligned reads in the region: chromosome 21: 19,000,000 - 20,000,000. The BAM files containing these reads for the cancer cell line and the matched normal are: HCC1143.normal.21.19M-20M.bam HCC1143.normal.21.19M-20M.bam.bai A lot of model-organism genomes are built-in IGV. Select the human genome version hg19 from the drop down menu: Select File > Load from File\u2026 from the main menu and select the BAM file HCC1143.normal.21.19M-20M.bam using the file browser. This BAM file only contains data for a 1 Megabase region of chromosome 21. Let\u2019s navigate there to see what genes this region covers. To do so, navigate to chr21:19,000,000-20,000,000 . Navigate to the gene CHODL by typing it in the search box. Load the dbsnp annotations by clicking File > Load From Server\u2026 > Annotations > Variation and Repeats > dbSNP 1.4.7 Like you did with the gene (i.e. by typing it in the search box), navigate to SNP rs3827160 that is annotated in the loaded file. Click on the coverage track where the SNP is: Exercise: What is the sequence coverage for that base? And the percentage T? Answer The coverage is 62, and 25 reads (40%) T. Navigate to region chr21:19,800,320-19,818,162 Load repeat tracks by selecting File > Load from Server\u2026 from the main menu and then select Annotations > Variation and Repeats > Repeat Masker Note This might take a while to load. Right click in the alignment track and select Color alignments by > insert size and pair orientation Exercise: Why are some reads coloured white? What can be the cause of that? Answer The white coloured reads have a map quality of 0 (click on the read to find the mapping quality). The cause of that is a LINE repeat region called L1PA3. Navigate to region chr21:19,324,500-19,331,500 Right click in the main alignment track and select: Expanded View as pairs Color alignments by > insert size and pair orientation Sort alignments by > insert size Exercise: What is the insert size of the red flagged read pairs? Can you estimate the size of the deletion? Answer The insert size is about 2.8 kb. This includes the reads. The deletion should be about 2.5 - 2.6 kb.","title":"HCC1143 data set"}]}